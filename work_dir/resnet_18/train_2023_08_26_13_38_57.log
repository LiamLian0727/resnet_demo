[2023-08-26 13:38:57 trainLogger INFO] : Random Seed: 42
[2023-08-26 13:38:57 trainLogger INFO] : device in: [device(type='cuda', index=0)]
[2023-08-26 13:38:57 trainLogger INFO] : train config: 
{'BATCH_SIZE': 256, 'BATCH_SIZE_IN_TEST': 128, 'NUM_WORKERS': 4, 'DATASET': 'cifar100', 'epoch': 100, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001, 'warmup': 5, 'mixup_args': {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.3, 'switch_prob': 0.5, 'mode': 'batch', 'label_smoothing': 0.1, 'num_classes': 100}}
[2023-08-26 13:38:57 trainLogger INFO] : module name: 
resnet_18
[2023-08-26 13:38:57 trainLogger INFO] : Lording Dataset: cifar100
[2023-08-26 13:38:59 trainLogger INFO] : Lording Dataset cifar100 successfully
[2023-08-26 13:39:00 trainLogger INFO] : params: 11.22M, FLOPs: 0.56B (in Tensor(1, 3, 32, 32))
[2023-08-26 13:39:04 trainLogger INFO] : module structure : 
DataParallel(
  (module): ResNet(
    (transforms): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0): Sequential(
        (0): Residual(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Residual(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Sequential(
        (0): Residual(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): Residual(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): Sequential(
        (0): Residual(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): Residual(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): Sequential(
        (0): Residual(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): Residual(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (out): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=100, bias=True)
    )
  )
)
[2023-08-26 13:39:04 trainLogger INFO] : Start training
[2023-08-26 13:39:05 trainLogger INFO] : epoch: 1/100, batch: 1/195, lr: 0.0000, loss 4.7182, grad_norm 4.54, Acc@1: 0.00%, Acc@5: 4.69%
[2023-08-26 13:39:08 trainLogger INFO] : epoch: 1/100, batch: 40/195, lr: 0.0040, loss 4.5211, grad_norm 3.54, Acc@1: 2.05%, Acc@5: 8.59%
[2023-08-26 13:39:11 trainLogger INFO] : epoch: 1/100, batch: 79/195, lr: 0.0080, loss 4.2066, grad_norm 3.17, Acc@1: 4.10%, Acc@5: 15.01%
[2023-08-26 13:39:14 trainLogger INFO] : epoch: 1/100, batch: 118/195, lr: 0.0120, loss 3.8383, grad_norm 3.33, Acc@1: 5.83%, Acc@5: 19.42%
[2023-08-26 13:39:17 trainLogger INFO] : epoch: 1/100, batch: 157/195, lr: 0.0160, loss 3.8155, grad_norm 3.44, Acc@1: 7.73%, Acc@5: 23.68%
[2023-08-26 13:39:20 trainLogger INFO] : epoch: 1/100, batch: 195/195, lr: 0.0199, loss 3.7457, grad_norm 3.60, Acc@1: 9.03%, Acc@5: 26.21%
[2023-08-26 13:39:20 trainLogger INFO] : EPOCH 1 training takes 0:00:16
[2023-08-26 13:39:21 trainLogger INFO] : [epoch 1] Acc@1: 15.09%, Acc@5: 39.53%, loss: 3.6005
[2023-08-26 13:39:22 trainLogger INFO] : epoch: 2/100, batch: 1/195, lr: 0.0200, loss 3.6317, grad_norm 3.38, Acc@1: 19.14%, Acc@5: 42.58%
[2023-08-26 13:39:25 trainLogger INFO] : epoch: 2/100, batch: 40/195, lr: 0.0240, loss 4.2763, grad_norm 2.79, Acc@1: 17.58%, Acc@5: 43.46%
[2023-08-26 13:39:28 trainLogger INFO] : epoch: 2/100, batch: 79/195, lr: 0.0280, loss 3.7279, grad_norm 2.81, Acc@1: 17.21%, Acc@5: 42.03%
[2023-08-26 13:39:31 trainLogger INFO] : epoch: 2/100, batch: 118/195, lr: 0.0320, loss 4.2962, grad_norm 2.50, Acc@1: 19.01%, Acc@5: 44.56%
[2023-08-26 13:39:34 trainLogger INFO] : epoch: 2/100, batch: 157/195, lr: 0.0360, loss 3.1881, grad_norm 2.70, Acc@1: 19.79%, Acc@5: 45.94%
[2023-08-26 13:39:37 trainLogger INFO] : epoch: 2/100, batch: 195/195, lr: 0.0399, loss 3.3005, grad_norm 2.74, Acc@1: 20.94%, Acc@5: 47.96%
[2023-08-26 13:39:37 trainLogger INFO] : EPOCH 2 training takes 0:00:15
[2023-08-26 13:39:39 trainLogger INFO] : [epoch 2] Acc@1: 24.99%, Acc@5: 56.10%, loss: 3.0058
[2023-08-26 13:39:39 trainLogger INFO] : epoch: 3/100, batch: 1/195, lr: 0.0400, loss 3.1325, grad_norm 3.18, Acc@1: 29.69%, Acc@5: 58.98%
[2023-08-26 13:39:42 trainLogger INFO] : epoch: 3/100, batch: 40/195, lr: 0.0440, loss 3.0047, grad_norm 2.81, Acc@1: 27.20%, Acc@5: 54.27%
[2023-08-26 13:39:45 trainLogger INFO] : epoch: 3/100, batch: 79/195, lr: 0.0480, loss 2.9021, grad_norm 2.71, Acc@1: 26.85%, Acc@5: 54.38%
[2023-08-26 13:39:48 trainLogger INFO] : epoch: 3/100, batch: 118/195, lr: 0.0520, loss 3.9333, grad_norm 2.08, Acc@1: 27.98%, Acc@5: 56.11%
[2023-08-26 13:39:51 trainLogger INFO] : epoch: 3/100, batch: 157/195, lr: 0.0560, loss 4.1275, grad_norm 2.10, Acc@1: 28.80%, Acc@5: 57.04%
[2023-08-26 13:39:54 trainLogger INFO] : epoch: 3/100, batch: 195/195, lr: 0.0599, loss 2.8759, grad_norm 2.25, Acc@1: 29.24%, Acc@5: 57.57%
[2023-08-26 13:39:54 trainLogger INFO] : EPOCH 3 training takes 0:00:15
[2023-08-26 13:39:56 trainLogger INFO] : [epoch 3] Acc@1: 33.83%, Acc@5: 65.04%, loss: 2.6343
[2023-08-26 13:39:57 trainLogger INFO] : epoch: 4/100, batch: 1/195, lr: 0.0600, loss 2.6794, grad_norm 2.27, Acc@1: 42.97%, Acc@5: 72.66%
[2023-08-26 13:40:00 trainLogger INFO] : epoch: 4/100, batch: 40/195, lr: 0.0640, loss 2.6674, grad_norm 2.29, Acc@1: 38.25%, Acc@5: 67.13%
[2023-08-26 13:40:03 trainLogger INFO] : epoch: 4/100, batch: 79/195, lr: 0.0680, loss 2.7304, grad_norm 2.35, Acc@1: 37.38%, Acc@5: 67.17%
[2023-08-26 13:40:06 trainLogger INFO] : epoch: 4/100, batch: 118/195, lr: 0.0720, loss 2.6967, grad_norm 2.08, Acc@1: 37.87%, Acc@5: 67.90%
[2023-08-26 13:40:09 trainLogger INFO] : epoch: 4/100, batch: 157/195, lr: 0.0760, loss 2.5143, grad_norm 1.89, Acc@1: 36.36%, Acc@5: 65.51%
[2023-08-26 13:40:12 trainLogger INFO] : epoch: 4/100, batch: 195/195, lr: 0.0799, loss 2.5646, grad_norm 1.89, Acc@1: 36.07%, Acc@5: 65.17%
[2023-08-26 13:40:12 trainLogger INFO] : EPOCH 4 training takes 0:00:15
[2023-08-26 13:40:13 trainLogger INFO] : [epoch 4] Acc@1: 41.06%, Acc@5: 72.25%, loss: 2.3028
[2023-08-26 13:40:14 trainLogger INFO] : epoch: 5/100, batch: 1/195, lr: 0.0800, loss 2.4756, grad_norm 1.80, Acc@1: 44.92%, Acc@5: 77.73%
[2023-08-26 13:40:17 trainLogger INFO] : epoch: 5/100, batch: 40/195, lr: 0.0840, loss 2.5155, grad_norm 2.10, Acc@1: 44.85%, Acc@5: 74.18%
[2023-08-26 13:40:20 trainLogger INFO] : epoch: 5/100, batch: 79/195, lr: 0.0880, loss 2.4347, grad_norm 1.92, Acc@1: 41.57%, Acc@5: 69.45%
[2023-08-26 13:40:23 trainLogger INFO] : epoch: 5/100, batch: 118/195, lr: 0.0920, loss 2.7301, grad_norm 1.93, Acc@1: 42.06%, Acc@5: 69.95%
[2023-08-26 13:40:26 trainLogger INFO] : epoch: 5/100, batch: 157/195, lr: 0.0960, loss 3.9160, grad_norm 1.65, Acc@1: 41.37%, Acc@5: 69.44%
[2023-08-26 13:40:29 trainLogger INFO] : epoch: 5/100, batch: 195/195, lr: 0.0999, loss 2.9900, grad_norm 1.81, Acc@1: 41.16%, Acc@5: 69.29%
[2023-08-26 13:40:29 trainLogger INFO] : EPOCH 5 training takes 0:00:15
[2023-08-26 13:40:31 trainLogger INFO] : [epoch 5] Acc@1: 47.64%, Acc@5: 77.90%, loss: 2.0383
[2023-08-26 13:40:31 trainLogger INFO] : epoch: 6/100, batch: 1/195, lr: 0.0994, loss 2.1801, grad_norm 1.75, Acc@1: 56.64%, Acc@5: 86.33%
[2023-08-26 13:40:34 trainLogger INFO] : epoch: 6/100, batch: 40/195, lr: 0.0993, loss 2.2729, grad_norm 1.71, Acc@1: 43.77%, Acc@5: 70.74%
[2023-08-26 13:40:37 trainLogger INFO] : epoch: 6/100, batch: 79/195, lr: 0.0993, loss 2.1791, grad_norm 1.60, Acc@1: 44.95%, Acc@5: 72.46%
[2023-08-26 13:40:40 trainLogger INFO] : epoch: 6/100, batch: 118/195, lr: 0.0992, loss 2.3688, grad_norm 1.72, Acc@1: 44.16%, Acc@5: 71.43%
[2023-08-26 13:40:43 trainLogger INFO] : epoch: 6/100, batch: 157/195, lr: 0.0992, loss 3.7740, grad_norm 1.72, Acc@1: 44.28%, Acc@5: 71.06%
[2023-08-26 13:40:46 trainLogger INFO] : epoch: 6/100, batch: 195/195, lr: 0.0991, loss 2.2163, grad_norm 1.59, Acc@1: 43.87%, Acc@5: 70.40%
[2023-08-26 13:40:46 trainLogger INFO] : EPOCH 6 training takes 0:00:15
[2023-08-26 13:40:48 trainLogger INFO] : [epoch 6] Acc@1: 49.27%, Acc@5: 78.91%, loss: 2.0133
[2023-08-26 13:40:48 trainLogger INFO] : epoch: 7/100, batch: 1/195, lr: 0.0991, loss 2.8158, grad_norm 1.55, Acc@1: 47.66%, Acc@5: 83.59%
[2023-08-26 13:40:52 trainLogger INFO] : epoch: 7/100, batch: 40/195, lr: 0.0991, loss 2.0279, grad_norm 1.65, Acc@1: 50.63%, Acc@5: 77.02%
[2023-08-26 13:40:55 trainLogger INFO] : epoch: 7/100, batch: 79/195, lr: 0.0990, loss 2.1348, grad_norm 1.61, Acc@1: 51.56%, Acc@5: 77.42%
[2023-08-26 13:40:58 trainLogger INFO] : epoch: 7/100, batch: 118/195, lr: 0.0989, loss 2.2019, grad_norm 1.62, Acc@1: 51.00%, Acc@5: 77.22%
[2023-08-26 13:41:01 trainLogger INFO] : epoch: 7/100, batch: 157/195, lr: 0.0989, loss 3.1646, grad_norm 1.53, Acc@1: 50.92%, Acc@5: 77.53%
[2023-08-26 13:41:04 trainLogger INFO] : epoch: 7/100, batch: 195/195, lr: 0.0988, loss 2.3819, grad_norm 1.49, Acc@1: 50.54%, Acc@5: 77.06%
[2023-08-26 13:41:04 trainLogger INFO] : EPOCH 7 training takes 0:00:15
[2023-08-26 13:41:05 trainLogger INFO] : [epoch 7] Acc@1: 55.75%, Acc@5: 83.82%, loss: 1.6906
[2023-08-26 13:41:06 trainLogger INFO] : epoch: 8/100, batch: 1/195, lr: 0.0988, loss 2.0562, grad_norm 1.54, Acc@1: 59.38%, Acc@5: 87.11%
[2023-08-26 13:41:09 trainLogger INFO] : epoch: 8/100, batch: 40/195, lr: 0.0987, loss 3.4937, grad_norm 1.50, Acc@1: 54.62%, Acc@5: 80.65%
[2023-08-26 13:41:12 trainLogger INFO] : epoch: 8/100, batch: 79/195, lr: 0.0987, loss 1.9799, grad_norm 1.55, Acc@1: 54.93%, Acc@5: 80.52%
[2023-08-26 13:41:15 trainLogger INFO] : epoch: 8/100, batch: 118/195, lr: 0.0986, loss 1.9867, grad_norm 1.54, Acc@1: 52.57%, Acc@5: 77.68%
[2023-08-26 13:41:18 trainLogger INFO] : epoch: 8/100, batch: 157/195, lr: 0.0985, loss 1.9087, grad_norm 1.45, Acc@1: 52.36%, Acc@5: 77.27%
[2023-08-26 13:41:21 trainLogger INFO] : epoch: 8/100, batch: 195/195, lr: 0.0984, loss 1.9329, grad_norm 1.59, Acc@1: 53.24%, Acc@5: 78.02%
[2023-08-26 13:41:21 trainLogger INFO] : EPOCH 8 training takes 0:00:15
[2023-08-26 13:41:23 trainLogger INFO] : [epoch 8] Acc@1: 59.52%, Acc@5: 86.14%, loss: 1.5368
[2023-08-26 13:41:23 trainLogger INFO] : epoch: 9/100, batch: 1/195, lr: 0.0984, loss 1.8543, grad_norm 1.42, Acc@1: 67.19%, Acc@5: 89.45%
[2023-08-26 13:41:26 trainLogger INFO] : epoch: 9/100, batch: 40/195, lr: 0.0984, loss 3.6637, grad_norm 1.57, Acc@1: 56.60%, Acc@5: 80.22%
[2023-08-26 13:41:29 trainLogger INFO] : epoch: 9/100, batch: 79/195, lr: 0.0983, loss 3.5909, grad_norm 1.63, Acc@1: 57.29%, Acc@5: 81.06%
[2023-08-26 13:41:32 trainLogger INFO] : epoch: 9/100, batch: 118/195, lr: 0.0982, loss 1.8469, grad_norm 1.54, Acc@1: 56.16%, Acc@5: 79.89%
[2023-08-26 13:41:35 trainLogger INFO] : epoch: 9/100, batch: 157/195, lr: 0.0981, loss 1.9421, grad_norm 1.57, Acc@1: 55.10%, Acc@5: 78.48%
[2023-08-26 13:41:38 trainLogger INFO] : epoch: 9/100, batch: 195/195, lr: 0.0980, loss 1.9192, grad_norm 1.50, Acc@1: 55.68%, Acc@5: 79.22%
[2023-08-26 13:41:38 trainLogger INFO] : EPOCH 9 training takes 0:00:15
[2023-08-26 13:41:40 trainLogger INFO] : [epoch 9] Acc@1: 57.69%, Acc@5: 85.27%, loss: 1.6142
[2023-08-26 13:41:41 trainLogger INFO] : epoch: 10/100, batch: 1/195, lr: 0.0980, loss 1.8418, grad_norm 1.49, Acc@1: 67.19%, Acc@5: 90.62%
[2023-08-26 13:41:44 trainLogger INFO] : epoch: 10/100, batch: 40/195, lr: 0.0979, loss 3.5282, grad_norm 1.54, Acc@1: 61.77%, Acc@5: 85.08%
[2023-08-26 13:41:47 trainLogger INFO] : epoch: 10/100, batch: 79/195, lr: 0.0978, loss 1.8006, grad_norm 1.54, Acc@1: 58.96%, Acc@5: 81.25%
[2023-08-26 13:41:50 trainLogger INFO] : epoch: 10/100, batch: 118/195, lr: 0.0977, loss 1.8498, grad_norm 1.62, Acc@1: 60.31%, Acc@5: 82.70%
[2023-08-26 13:41:53 trainLogger INFO] : epoch: 10/100, batch: 157/195, lr: 0.0976, loss 1.8387, grad_norm 1.56, Acc@1: 59.86%, Acc@5: 82.32%
[2023-08-26 13:41:56 trainLogger INFO] : epoch: 10/100, batch: 195/195, lr: 0.0976, loss 1.7081, grad_norm 1.41, Acc@1: 59.02%, Acc@5: 81.54%
[2023-08-26 13:41:56 trainLogger INFO] : EPOCH 10 training takes 0:00:15
[2023-08-26 13:41:57 trainLogger INFO] : [epoch 10] Acc@1: 60.06%, Acc@5: 86.39%, loss: 1.5048
[2023-08-26 13:41:58 trainLogger INFO] : epoch: 11/100, batch: 1/195, lr: 0.0976, loss 3.0305, grad_norm 1.50, Acc@1: 51.95%, Acc@5: 80.47%
[2023-08-26 13:42:01 trainLogger INFO] : epoch: 11/100, batch: 40/195, lr: 0.0975, loss 1.6121, grad_norm 1.44, Acc@1: 63.54%, Acc@5: 84.25%
[2023-08-26 13:42:04 trainLogger INFO] : epoch: 11/100, batch: 79/195, lr: 0.0974, loss 1.6766, grad_norm 1.51, Acc@1: 67.03%, Acc@5: 87.90%
[2023-08-26 13:42:07 trainLogger INFO] : epoch: 11/100, batch: 118/195, lr: 0.0973, loss 1.8065, grad_norm 1.60, Acc@1: 65.01%, Acc@5: 86.28%
[2023-08-26 13:42:10 trainLogger INFO] : epoch: 11/100, batch: 157/195, lr: 0.0971, loss 1.6979, grad_norm 1.48, Acc@1: 63.71%, Acc@5: 85.01%
[2023-08-26 13:42:13 trainLogger INFO] : epoch: 11/100, batch: 195/195, lr: 0.0970, loss 1.6723, grad_norm 1.50, Acc@1: 63.37%, Acc@5: 84.82%
[2023-08-26 13:42:13 trainLogger INFO] : EPOCH 11 training takes 0:00:15
[2023-08-26 13:42:15 trainLogger INFO] : [epoch 11] Acc@1: 61.52%, Acc@5: 86.94%, loss: 1.5123
[2023-08-26 13:42:15 trainLogger INFO] : epoch: 12/100, batch: 1/195, lr: 0.0970, loss 1.7317, grad_norm 1.47, Acc@1: 71.09%, Acc@5: 92.19%
[2023-08-26 13:42:18 trainLogger INFO] : epoch: 12/100, batch: 40/195, lr: 0.0969, loss 1.5733, grad_norm 1.42, Acc@1: 61.50%, Acc@5: 82.28%
[2023-08-26 13:42:21 trainLogger INFO] : epoch: 12/100, batch: 79/195, lr: 0.0968, loss 1.5883, grad_norm 1.43, Acc@1: 65.26%, Acc@5: 85.38%
[2023-08-26 13:42:24 trainLogger INFO] : epoch: 12/100, batch: 118/195, lr: 0.0967, loss 3.6065, grad_norm 1.57, Acc@1: 63.28%, Acc@5: 83.54%
[2023-08-26 13:42:27 trainLogger INFO] : epoch: 12/100, batch: 157/195, lr: 0.0966, loss 1.5526, grad_norm 1.44, Acc@1: 63.48%, Acc@5: 83.40%
[2023-08-26 13:42:30 trainLogger INFO] : epoch: 12/100, batch: 195/195, lr: 0.0965, loss 3.2154, grad_norm 1.58, Acc@1: 63.20%, Acc@5: 83.21%
[2023-08-26 13:42:30 trainLogger INFO] : EPOCH 12 training takes 0:00:15
[2023-08-26 13:42:32 trainLogger INFO] : [epoch 12] Acc@1: 62.07%, Acc@5: 87.13%, loss: 1.4909
[2023-08-26 13:42:33 trainLogger INFO] : epoch: 13/100, batch: 1/195, lr: 0.0965, loss 1.4892, grad_norm 1.44, Acc@1: 78.91%, Acc@5: 97.27%
[2023-08-26 13:42:36 trainLogger INFO] : epoch: 13/100, batch: 40/195, lr: 0.0964, loss 1.5220, grad_norm 1.41, Acc@1: 65.77%, Acc@5: 84.20%
[2023-08-26 13:42:39 trainLogger INFO] : epoch: 13/100, batch: 79/195, lr: 0.0963, loss 2.3233, grad_norm 1.57, Acc@1: 65.38%, Acc@5: 83.95%
[2023-08-26 13:42:42 trainLogger INFO] : epoch: 13/100, batch: 118/195, lr: 0.0961, loss 1.5482, grad_norm 1.51, Acc@1: 65.82%, Acc@5: 84.21%
[2023-08-26 13:42:45 trainLogger INFO] : epoch: 13/100, batch: 157/195, lr: 0.0960, loss 2.3728, grad_norm 1.50, Acc@1: 66.44%, Acc@5: 85.01%
[2023-08-26 13:42:48 trainLogger INFO] : epoch: 13/100, batch: 195/195, lr: 0.0959, loss 1.7646, grad_norm 1.54, Acc@1: 64.28%, Acc@5: 83.59%
[2023-08-26 13:42:48 trainLogger INFO] : EPOCH 13 training takes 0:00:15
[2023-08-26 13:42:49 trainLogger INFO] : [epoch 13] Acc@1: 61.93%, Acc@5: 86.84%, loss: 1.4893
[2023-08-26 13:42:50 trainLogger INFO] : epoch: 14/100, batch: 1/195, lr: 0.0959, loss 1.3555, grad_norm 1.20, Acc@1: 85.55%, Acc@5: 96.48%
[2023-08-26 13:42:53 trainLogger INFO] : epoch: 14/100, batch: 40/195, lr: 0.0958, loss 1.4723, grad_norm 1.42, Acc@1: 60.33%, Acc@5: 78.12%
[2023-08-26 13:42:56 trainLogger INFO] : epoch: 14/100, batch: 79/195, lr: 0.0956, loss 3.0168, grad_norm 1.67, Acc@1: 65.65%, Acc@5: 83.43%
[2023-08-26 13:42:59 trainLogger INFO] : epoch: 14/100, batch: 118/195, lr: 0.0955, loss 1.4752, grad_norm 1.50, Acc@1: 67.08%, Acc@5: 84.82%
[2023-08-26 13:43:02 trainLogger INFO] : epoch: 14/100, batch: 157/195, lr: 0.0954, loss 1.4840, grad_norm 1.42, Acc@1: 67.72%, Acc@5: 86.04%
[2023-08-26 13:43:05 trainLogger INFO] : epoch: 14/100, batch: 195/195, lr: 0.0952, loss 1.5627, grad_norm 1.56, Acc@1: 66.72%, Acc@5: 84.95%
[2023-08-26 13:43:05 trainLogger INFO] : EPOCH 14 training takes 0:00:15
[2023-08-26 13:43:07 trainLogger INFO] : [epoch 14] Acc@1: 60.88%, Acc@5: 86.72%, loss: 1.5216
[2023-08-26 13:43:07 trainLogger INFO] : epoch: 15/100, batch: 1/195, lr: 0.0952, loss 1.4385, grad_norm 1.36, Acc@1: 82.03%, Acc@5: 95.70%
[2023-08-26 13:43:10 trainLogger INFO] : epoch: 15/100, batch: 40/195, lr: 0.0951, loss 1.3992, grad_norm 1.39, Acc@1: 73.19%, Acc@5: 88.22%
[2023-08-26 13:43:13 trainLogger INFO] : epoch: 15/100, batch: 79/195, lr: 0.0950, loss 1.4593, grad_norm 1.42, Acc@1: 66.81%, Acc@5: 82.10%
[2023-08-26 13:43:16 trainLogger INFO] : epoch: 15/100, batch: 118/195, lr: 0.0948, loss 1.5363, grad_norm 1.49, Acc@1: 66.19%, Acc@5: 82.78%
[2023-08-26 13:43:19 trainLogger INFO] : epoch: 15/100, batch: 157/195, lr: 0.0947, loss 1.4428, grad_norm 1.41, Acc@1: 66.05%, Acc@5: 82.87%
[2023-08-26 13:43:22 trainLogger INFO] : epoch: 15/100, batch: 195/195, lr: 0.0946, loss 1.5033, grad_norm 1.53, Acc@1: 67.15%, Acc@5: 84.22%
[2023-08-26 13:43:22 trainLogger INFO] : EPOCH 15 training takes 0:00:15
[2023-08-26 13:43:24 trainLogger INFO] : [epoch 15] Acc@1: 64.02%, Acc@5: 88.50%, loss: 1.3929
[2023-08-26 13:43:25 trainLogger INFO] : epoch: 16/100, batch: 1/195, lr: 0.0946, loss 1.3290, grad_norm 1.36, Acc@1: 84.77%, Acc@5: 98.05%
[2023-08-26 13:43:28 trainLogger INFO] : epoch: 16/100, batch: 40/195, lr: 0.0944, loss 3.4685, grad_norm 1.95, Acc@1: 69.22%, Acc@5: 84.04%
[2023-08-26 13:43:31 trainLogger INFO] : epoch: 16/100, batch: 79/195, lr: 0.0943, loss 1.3430, grad_norm 1.39, Acc@1: 68.38%, Acc@5: 84.29%
[2023-08-26 13:43:34 trainLogger INFO] : epoch: 16/100, batch: 118/195, lr: 0.0941, loss 1.3756, grad_norm 1.39, Acc@1: 67.30%, Acc@5: 83.18%
[2023-08-26 13:43:37 trainLogger INFO] : epoch: 16/100, batch: 157/195, lr: 0.0940, loss 1.4330, grad_norm 1.55, Acc@1: 68.18%, Acc@5: 84.06%
[2023-08-26 13:43:40 trainLogger INFO] : epoch: 16/100, batch: 195/195, lr: 0.0938, loss 3.0432, grad_norm 1.61, Acc@1: 68.26%, Acc@5: 84.29%
[2023-08-26 13:43:40 trainLogger INFO] : EPOCH 16 training takes 0:00:15
[2023-08-26 13:43:41 trainLogger INFO] : [epoch 16] Acc@1: 62.64%, Acc@5: 86.55%, loss: 1.5246
[2023-08-26 13:43:42 trainLogger INFO] : epoch: 17/100, batch: 1/195, lr: 0.0938, loss 1.2989, grad_norm 1.28, Acc@1: 87.50%, Acc@5: 96.88%
[2023-08-26 13:43:45 trainLogger INFO] : epoch: 17/100, batch: 40/195, lr: 0.0937, loss 1.3419, grad_norm 1.43, Acc@1: 73.82%, Acc@5: 87.92%
[2023-08-26 13:43:48 trainLogger INFO] : epoch: 17/100, batch: 79/195, lr: 0.0935, loss 1.2859, grad_norm 1.29, Acc@1: 77.03%, Acc@5: 90.93%
[2023-08-26 13:43:51 trainLogger INFO] : epoch: 17/100, batch: 118/195, lr: 0.0934, loss 1.3078, grad_norm 1.35, Acc@1: 73.01%, Acc@5: 86.95%
[2023-08-26 13:43:54 trainLogger INFO] : epoch: 17/100, batch: 157/195, lr: 0.0932, loss 1.3645, grad_norm 1.43, Acc@1: 70.31%, Acc@5: 84.24%
[2023-08-26 13:43:57 trainLogger INFO] : epoch: 17/100, batch: 195/195, lr: 0.0930, loss 1.4437, grad_norm 1.55, Acc@1: 70.52%, Acc@5: 84.94%
[2023-08-26 13:43:57 trainLogger INFO] : EPOCH 17 training takes 0:00:15
[2023-08-26 13:43:58 trainLogger INFO] : [epoch 17] Acc@1: 63.65%, Acc@5: 88.12%, loss: 1.4226
[2023-08-26 13:43:59 trainLogger INFO] : epoch: 18/100, batch: 1/195, lr: 0.0930, loss 3.4729, grad_norm 2.14, Acc@1: 18.36%, Acc@5: 42.58%
[2023-08-26 13:44:02 trainLogger INFO] : epoch: 18/100, batch: 40/195, lr: 0.0929, loss 1.3761, grad_norm 1.47, Acc@1: 74.46%, Acc@5: 89.36%
[2023-08-26 13:44:05 trainLogger INFO] : epoch: 18/100, batch: 79/195, lr: 0.0927, loss 3.5419, grad_norm 1.83, Acc@1: 71.97%, Acc@5: 86.11%
[2023-08-26 13:44:08 trainLogger INFO] : epoch: 18/100, batch: 118/195, lr: 0.0925, loss 1.3240, grad_norm 1.46, Acc@1: 75.13%, Acc@5: 89.00%
[2023-08-26 13:44:11 trainLogger INFO] : epoch: 18/100, batch: 157/195, lr: 0.0924, loss 3.4983, grad_norm 2.02, Acc@1: 75.55%, Acc@5: 89.27%
[2023-08-26 13:44:14 trainLogger INFO] : epoch: 18/100, batch: 195/195, lr: 0.0922, loss 1.4513, grad_norm 1.64, Acc@1: 75.65%, Acc@5: 89.60%
[2023-08-26 13:44:14 trainLogger INFO] : EPOCH 18 training takes 0:00:15
[2023-08-26 13:44:16 trainLogger INFO] : [epoch 18] Acc@1: 63.49%, Acc@5: 87.82%, loss: 1.4155
[2023-08-26 13:44:16 trainLogger INFO] : epoch: 19/100, batch: 1/195, lr: 0.0922, loss 1.1712, grad_norm 1.22, Acc@1: 91.80%, Acc@5: 99.22%
[2023-08-26 13:44:19 trainLogger INFO] : epoch: 19/100, batch: 40/195, lr: 0.0920, loss 1.2048, grad_norm 1.27, Acc@1: 81.21%, Acc@5: 92.84%
[2023-08-26 13:44:22 trainLogger INFO] : epoch: 19/100, batch: 79/195, lr: 0.0919, loss 3.5373, grad_norm 2.01, Acc@1: 77.29%, Acc@5: 89.53%
[2023-08-26 13:44:26 trainLogger INFO] : epoch: 19/100, batch: 118/195, lr: 0.0917, loss 2.4931, grad_norm 1.51, Acc@1: 75.75%, Acc@5: 88.07%
[2023-08-26 13:44:29 trainLogger INFO] : epoch: 19/100, batch: 157/195, lr: 0.0915, loss 1.2497, grad_norm 1.35, Acc@1: 75.17%, Acc@5: 87.89%
[2023-08-26 13:44:31 trainLogger INFO] : epoch: 19/100, batch: 195/195, lr: 0.0914, loss 1.3842, grad_norm 1.56, Acc@1: 73.98%, Acc@5: 87.03%
[2023-08-26 13:44:32 trainLogger INFO] : EPOCH 19 training takes 0:00:15
[2023-08-26 13:44:33 trainLogger INFO] : [epoch 19] Acc@1: 63.11%, Acc@5: 86.96%, loss: 1.5037
[2023-08-26 13:44:34 trainLogger INFO] : epoch: 20/100, batch: 1/195, lr: 0.0914, loss 3.2919, grad_norm 1.90, Acc@1: 51.95%, Acc@5: 77.34%
[2023-08-26 13:44:37 trainLogger INFO] : epoch: 20/100, batch: 40/195, lr: 0.0912, loss 3.7244, grad_norm 2.47, Acc@1: 70.35%, Acc@5: 84.91%
[2023-08-26 13:44:40 trainLogger INFO] : epoch: 20/100, batch: 79/195, lr: 0.0910, loss 2.6452, grad_norm 1.43, Acc@1: 74.48%, Acc@5: 88.35%
[2023-08-26 13:44:43 trainLogger INFO] : epoch: 20/100, batch: 118/195, lr: 0.0908, loss 1.3049, grad_norm 1.55, Acc@1: 76.65%, Acc@5: 89.68%
[2023-08-26 13:44:46 trainLogger INFO] : epoch: 20/100, batch: 157/195, lr: 0.0906, loss 1.7504, grad_norm 1.43, Acc@1: 74.60%, Acc@5: 86.95%
[2023-08-26 13:44:49 trainLogger INFO] : epoch: 20/100, batch: 195/195, lr: 0.0905, loss 1.2741, grad_norm 1.46, Acc@1: 74.99%, Acc@5: 87.67%
[2023-08-26 13:44:49 trainLogger INFO] : EPOCH 20 training takes 0:00:15
[2023-08-26 13:44:50 trainLogger INFO] : [epoch 20] Acc@1: 65.46%, Acc@5: 88.77%, loss: 1.3755
[2023-08-26 13:44:51 trainLogger INFO] : epoch: 21/100, batch: 1/195, lr: 0.0905, loss 1.3067, grad_norm 1.22, Acc@1: 0.39%, Acc@5: 5.47%
[2023-08-26 13:44:54 trainLogger INFO] : epoch: 21/100, batch: 40/195, lr: 0.0903, loss 1.0767, grad_norm 1.11, Acc@1: 84.52%, Acc@5: 93.15%
[2023-08-26 13:44:57 trainLogger INFO] : epoch: 21/100, batch: 79/195, lr: 0.0901, loss 3.4045, grad_norm 1.86, Acc@1: 81.19%, Acc@5: 92.12%
[2023-08-26 13:45:00 trainLogger INFO] : epoch: 21/100, batch: 118/195, lr: 0.0899, loss 1.1654, grad_norm 1.25, Acc@1: 79.71%, Acc@5: 90.86%
[2023-08-26 13:45:03 trainLogger INFO] : epoch: 21/100, batch: 157/195, lr: 0.0897, loss 3.3083, grad_norm 1.82, Acc@1: 76.73%, Acc@5: 87.49%
[2023-08-26 13:45:06 trainLogger INFO] : epoch: 21/100, batch: 195/195, lr: 0.0895, loss 3.1341, grad_norm 1.89, Acc@1: 77.36%, Acc@5: 88.00%
[2023-08-26 13:45:06 trainLogger INFO] : EPOCH 21 training takes 0:00:15
[2023-08-26 13:45:08 trainLogger INFO] : [epoch 21] Acc@1: 63.76%, Acc@5: 87.48%, loss: 1.4980
[2023-08-26 13:45:08 trainLogger INFO] : epoch: 22/100, batch: 1/195, lr: 0.0895, loss 1.1886, grad_norm 1.47, Acc@1: 89.06%, Acc@5: 99.22%
[2023-08-26 13:45:11 trainLogger INFO] : epoch: 22/100, batch: 40/195, lr: 0.0893, loss 1.1575, grad_norm 1.22, Acc@1: 79.83%, Acc@5: 91.03%
[2023-08-26 13:45:14 trainLogger INFO] : epoch: 22/100, batch: 79/195, lr: 0.0891, loss 1.2185, grad_norm 1.38, Acc@1: 79.42%, Acc@5: 90.17%
[2023-08-26 13:45:18 trainLogger INFO] : epoch: 22/100, batch: 118/195, lr: 0.0889, loss 1.1529, grad_norm 1.24, Acc@1: 80.96%, Acc@5: 91.29%
[2023-08-26 13:45:21 trainLogger INFO] : epoch: 22/100, batch: 157/195, lr: 0.0887, loss 1.1692, grad_norm 1.34, Acc@1: 79.43%, Acc@5: 90.14%
[2023-08-26 13:45:23 trainLogger INFO] : epoch: 22/100, batch: 195/195, lr: 0.0885, loss 1.1816, grad_norm 1.41, Acc@1: 79.02%, Acc@5: 89.72%
[2023-08-26 13:45:24 trainLogger INFO] : EPOCH 22 training takes 0:00:15
[2023-08-26 13:45:25 trainLogger INFO] : [epoch 22] Acc@1: 65.23%, Acc@5: 88.82%, loss: 1.3542
[2023-08-26 13:45:26 trainLogger INFO] : epoch: 23/100, batch: 1/195, lr: 0.0885, loss 1.0727, grad_norm 1.01, Acc@1: 94.14%, Acc@5: 98.83%
[2023-08-26 13:45:29 trainLogger INFO] : epoch: 23/100, batch: 40/195, lr: 0.0883, loss 2.1330, grad_norm 1.33, Acc@1: 80.93%, Acc@5: 89.65%
[2023-08-26 13:45:32 trainLogger INFO] : epoch: 23/100, batch: 79/195, lr: 0.0881, loss 1.1821, grad_norm 1.33, Acc@1: 80.79%, Acc@5: 90.04%
[2023-08-26 13:45:35 trainLogger INFO] : epoch: 23/100, batch: 118/195, lr: 0.0879, loss 1.1387, grad_norm 1.26, Acc@1: 81.08%, Acc@5: 90.55%
[2023-08-26 13:45:38 trainLogger INFO] : epoch: 23/100, batch: 157/195, lr: 0.0877, loss 1.1646, grad_norm 1.30, Acc@1: 81.69%, Acc@5: 91.34%
[2023-08-26 13:45:41 trainLogger INFO] : epoch: 23/100, batch: 195/195, lr: 0.0875, loss 1.2384, grad_norm 1.45, Acc@1: 80.75%, Acc@5: 90.99%
[2023-08-26 13:45:41 trainLogger INFO] : EPOCH 23 training takes 0:00:15
[2023-08-26 13:45:42 trainLogger INFO] : [epoch 23] Acc@1: 65.14%, Acc@5: 88.18%, loss: 1.4384
[2023-08-26 13:45:43 trainLogger INFO] : epoch: 24/100, batch: 1/195, lr: 0.0875, loss 1.1398, grad_norm 1.31, Acc@1: 93.36%, Acc@5: 98.44%
[2023-08-26 13:45:46 trainLogger INFO] : epoch: 24/100, batch: 40/195, lr: 0.0873, loss 1.1267, grad_norm 1.26, Acc@1: 80.94%, Acc@5: 91.69%
[2023-08-26 13:45:49 trainLogger INFO] : epoch: 24/100, batch: 79/195, lr: 0.0871, loss 1.2303, grad_norm 1.41, Acc@1: 80.21%, Acc@5: 90.54%
[2023-08-26 13:45:52 trainLogger INFO] : epoch: 24/100, batch: 118/195, lr: 0.0869, loss 3.2106, grad_norm 1.90, Acc@1: 79.85%, Acc@5: 89.38%
[2023-08-26 13:45:55 trainLogger INFO] : epoch: 24/100, batch: 157/195, lr: 0.0867, loss 1.0936, grad_norm 1.23, Acc@1: 81.82%, Acc@5: 91.15%
[2023-08-26 13:45:58 trainLogger INFO] : epoch: 24/100, batch: 195/195, lr: 0.0865, loss 1.2417, grad_norm 1.53, Acc@1: 79.60%, Acc@5: 89.57%
[2023-08-26 13:45:58 trainLogger INFO] : EPOCH 24 training takes 0:00:15
[2023-08-26 13:46:00 trainLogger INFO] : [epoch 24] Acc@1: 64.50%, Acc@5: 87.82%, loss: 1.4562
[2023-08-26 13:46:00 trainLogger INFO] : epoch: 25/100, batch: 1/195, lr: 0.0864, loss 3.6251, grad_norm 1.97, Acc@1: 20.70%, Acc@5: 48.44%
[2023-08-26 13:46:03 trainLogger INFO] : epoch: 25/100, batch: 40/195, lr: 0.0862, loss 1.1477, grad_norm 1.19, Acc@1: 71.92%, Acc@5: 84.81%
[2023-08-26 13:46:06 trainLogger INFO] : epoch: 25/100, batch: 79/195, lr: 0.0860, loss 1.0518, grad_norm 1.04, Acc@1: 76.34%, Acc@5: 88.27%
[2023-08-26 13:46:09 trainLogger INFO] : epoch: 25/100, batch: 118/195, lr: 0.0858, loss 1.0545, grad_norm 1.15, Acc@1: 78.08%, Acc@5: 89.02%
[2023-08-26 13:46:12 trainLogger INFO] : epoch: 25/100, batch: 157/195, lr: 0.0856, loss 2.9654, grad_norm 1.76, Acc@1: 76.44%, Acc@5: 87.61%
[2023-08-26 13:46:15 trainLogger INFO] : epoch: 25/100, batch: 195/195, lr: 0.0854, loss 1.1002, grad_norm 1.26, Acc@1: 77.48%, Acc@5: 88.30%
[2023-08-26 13:46:16 trainLogger INFO] : EPOCH 25 training takes 0:00:15
[2023-08-26 13:46:17 trainLogger INFO] : [epoch 25] Acc@1: 65.91%, Acc@5: 88.62%, loss: 1.3689
[2023-08-26 13:46:18 trainLogger INFO] : epoch: 26/100, batch: 1/195, lr: 0.0854, loss 1.0904, grad_norm 1.22, Acc@1: 91.80%, Acc@5: 97.66%
[2023-08-26 13:46:21 trainLogger INFO] : epoch: 26/100, batch: 40/195, lr: 0.0851, loss 1.0764, grad_norm 1.24, Acc@1: 79.55%, Acc@5: 88.29%
[2023-08-26 13:46:24 trainLogger INFO] : epoch: 26/100, batch: 79/195, lr: 0.0849, loss 1.0545, grad_norm 1.11, Acc@1: 78.89%, Acc@5: 87.61%
[2023-08-26 13:46:27 trainLogger INFO] : epoch: 26/100, batch: 118/195, lr: 0.0847, loss 1.1766, grad_norm 1.36, Acc@1: 79.21%, Acc@5: 88.48%
[2023-08-26 13:46:30 trainLogger INFO] : epoch: 26/100, batch: 157/195, lr: 0.0845, loss 1.0713, grad_norm 1.20, Acc@1: 79.67%, Acc@5: 89.19%
[2023-08-26 13:46:33 trainLogger INFO] : epoch: 26/100, batch: 195/195, lr: 0.0842, loss 1.1048, grad_norm 1.20, Acc@1: 80.55%, Acc@5: 89.88%
[2023-08-26 13:46:33 trainLogger INFO] : EPOCH 26 training takes 0:00:15
[2023-08-26 13:46:34 trainLogger INFO] : [epoch 26] Acc@1: 66.57%, Acc@5: 88.87%, loss: 1.3531
[2023-08-26 13:46:35 trainLogger INFO] : epoch: 27/100, batch: 1/195, lr: 0.0842, loss 3.1050, grad_norm 1.85, Acc@1: 51.56%, Acc@5: 81.25%
[2023-08-26 13:46:38 trainLogger INFO] : epoch: 27/100, batch: 40/195, lr: 0.0840, loss 1.9935, grad_norm 1.30, Acc@1: 77.90%, Acc@5: 88.12%
[2023-08-26 13:46:41 trainLogger INFO] : epoch: 27/100, batch: 79/195, lr: 0.0838, loss 3.3108, grad_norm 2.21, Acc@1: 78.12%, Acc@5: 87.99%
[2023-08-26 13:46:44 trainLogger INFO] : epoch: 27/100, batch: 118/195, lr: 0.0835, loss 1.0898, grad_norm 1.24, Acc@1: 80.66%, Acc@5: 90.19%
[2023-08-26 13:46:47 trainLogger INFO] : epoch: 27/100, batch: 157/195, lr: 0.0833, loss 1.0779, grad_norm 1.32, Acc@1: 78.87%, Acc@5: 88.41%
[2023-08-26 13:46:50 trainLogger INFO] : epoch: 27/100, batch: 195/195, lr: 0.0831, loss 1.7129, grad_norm 1.52, Acc@1: 79.96%, Acc@5: 89.38%
[2023-08-26 13:46:50 trainLogger INFO] : EPOCH 27 training takes 0:00:15
[2023-08-26 13:46:51 trainLogger INFO] : [epoch 27] Acc@1: 66.25%, Acc@5: 88.48%, loss: 1.3806
[2023-08-26 13:46:52 trainLogger INFO] : epoch: 28/100, batch: 1/195, lr: 0.0831, loss 3.1633, grad_norm 1.89, Acc@1: 41.80%, Acc@5: 75.78%
[2023-08-26 13:46:55 trainLogger INFO] : epoch: 28/100, batch: 40/195, lr: 0.0828, loss 2.4541, grad_norm 1.51, Acc@1: 86.50%, Acc@5: 94.37%
[2023-08-26 13:46:58 trainLogger INFO] : epoch: 28/100, batch: 79/195, lr: 0.0826, loss 1.0879, grad_norm 1.31, Acc@1: 80.17%, Acc@5: 88.66%
[2023-08-26 13:47:01 trainLogger INFO] : epoch: 28/100, batch: 118/195, lr: 0.0824, loss 1.9470, grad_norm 1.81, Acc@1: 78.98%, Acc@5: 88.05%
[2023-08-26 13:47:04 trainLogger INFO] : epoch: 28/100, batch: 157/195, lr: 0.0821, loss 1.0437, grad_norm 1.12, Acc@1: 80.28%, Acc@5: 88.91%
[2023-08-26 13:47:07 trainLogger INFO] : epoch: 28/100, batch: 195/195, lr: 0.0819, loss 1.0902, grad_norm 1.31, Acc@1: 78.67%, Acc@5: 87.79%
[2023-08-26 13:47:07 trainLogger INFO] : EPOCH 28 training takes 0:00:15
[2023-08-26 13:47:08 trainLogger INFO] : [epoch 28] Acc@1: 65.65%, Acc@5: 88.16%, loss: 1.4130
[2023-08-26 13:47:09 trainLogger INFO] : epoch: 29/100, batch: 1/195, lr: 0.0819, loss 3.0400, grad_norm 1.95, Acc@1: 54.30%, Acc@5: 83.98%
[2023-08-26 13:47:12 trainLogger INFO] : epoch: 29/100, batch: 40/195, lr: 0.0816, loss 0.9997, grad_norm 0.97, Acc@1: 79.90%, Acc@5: 89.31%
[2023-08-26 13:47:15 trainLogger INFO] : epoch: 29/100, batch: 79/195, lr: 0.0814, loss 0.9846, grad_norm 0.98, Acc@1: 76.92%, Acc@5: 87.08%
[2023-08-26 13:47:18 trainLogger INFO] : epoch: 29/100, batch: 118/195, lr: 0.0811, loss 1.0879, grad_norm 1.26, Acc@1: 77.64%, Acc@5: 87.05%
[2023-08-26 13:47:21 trainLogger INFO] : epoch: 29/100, batch: 157/195, lr: 0.0809, loss 1.0490, grad_norm 1.17, Acc@1: 80.09%, Acc@5: 89.03%
[2023-08-26 13:47:24 trainLogger INFO] : epoch: 29/100, batch: 195/195, lr: 0.0807, loss 2.5404, grad_norm 1.71, Acc@1: 79.16%, Acc@5: 88.40%
[2023-08-26 13:47:24 trainLogger INFO] : EPOCH 29 training takes 0:00:15
[2023-08-26 13:47:26 trainLogger INFO] : [epoch 29] Acc@1: 65.35%, Acc@5: 88.02%, loss: 1.4653
[2023-08-26 13:47:26 trainLogger INFO] : epoch: 30/100, batch: 1/195, lr: 0.0806, loss 1.0240, grad_norm 1.07, Acc@1: 95.31%, Acc@5: 99.22%
[2023-08-26 13:47:29 trainLogger INFO] : epoch: 30/100, batch: 40/195, lr: 0.0804, loss 0.9820, grad_norm 0.97, Acc@1: 87.72%, Acc@5: 93.56%
[2023-08-26 13:47:32 trainLogger INFO] : epoch: 30/100, batch: 79/195, lr: 0.0801, loss 1.0520, grad_norm 1.23, Acc@1: 84.36%, Acc@5: 91.21%
[2023-08-26 13:47:35 trainLogger INFO] : epoch: 30/100, batch: 118/195, lr: 0.0799, loss 1.0486, grad_norm 1.23, Acc@1: 84.26%, Acc@5: 91.21%
[2023-08-26 13:47:38 trainLogger INFO] : epoch: 30/100, batch: 157/195, lr: 0.0796, loss 1.0425, grad_norm 1.14, Acc@1: 83.95%, Acc@5: 90.80%
[2023-08-26 13:47:41 trainLogger INFO] : epoch: 30/100, batch: 195/195, lr: 0.0794, loss 1.0271, grad_norm 1.22, Acc@1: 84.10%, Acc@5: 91.46%
[2023-08-26 13:47:41 trainLogger INFO] : EPOCH 30 training takes 0:00:15
[2023-08-26 13:47:43 trainLogger INFO] : [epoch 30] Acc@1: 65.97%, Acc@5: 88.27%, loss: 1.3907
[2023-08-26 13:47:44 trainLogger INFO] : epoch: 31/100, batch: 1/195, lr: 0.0794, loss 1.0035, grad_norm 1.03, Acc@1: 95.31%, Acc@5: 99.22%
[2023-08-26 13:47:47 trainLogger INFO] : epoch: 31/100, batch: 40/195, lr: 0.0791, loss 0.9985, grad_norm 1.10, Acc@1: 86.91%, Acc@5: 93.89%
[2023-08-26 13:47:50 trainLogger INFO] : epoch: 31/100, batch: 79/195, lr: 0.0789, loss 1.0647, grad_norm 1.26, Acc@1: 84.44%, Acc@5: 91.80%
[2023-08-26 13:47:53 trainLogger INFO] : epoch: 31/100, batch: 118/195, lr: 0.0786, loss 1.1833, grad_norm 1.16, Acc@1: 83.23%, Acc@5: 90.56%
[2023-08-26 13:47:56 trainLogger INFO] : epoch: 31/100, batch: 157/195, lr: 0.0784, loss 3.4121, grad_norm 2.32, Acc@1: 81.14%, Acc@5: 89.74%
[2023-08-26 13:47:59 trainLogger INFO] : epoch: 31/100, batch: 195/195, lr: 0.0781, loss 1.0385, grad_norm 1.14, Acc@1: 80.63%, Acc@5: 89.21%
[2023-08-26 13:47:59 trainLogger INFO] : EPOCH 31 training takes 0:00:15
[2023-08-26 13:48:00 trainLogger INFO] : [epoch 31] Acc@1: 67.39%, Acc@5: 89.00%, loss: 1.3287
[2023-08-26 13:48:01 trainLogger INFO] : epoch: 32/100, batch: 1/195, lr: 0.0781, loss 1.0116, grad_norm 1.03, Acc@1: 96.48%, Acc@5: 99.61%
[2023-08-26 13:48:04 trainLogger INFO] : epoch: 32/100, batch: 40/195, lr: 0.0778, loss 3.1167, grad_norm 1.91, Acc@1: 85.87%, Acc@5: 92.33%
[2023-08-26 13:48:07 trainLogger INFO] : epoch: 32/100, batch: 79/195, lr: 0.0776, loss 0.9829, grad_norm 1.02, Acc@1: 82.83%, Acc@5: 89.80%
[2023-08-26 13:48:10 trainLogger INFO] : epoch: 32/100, batch: 118/195, lr: 0.0773, loss 2.8823, grad_norm 1.91, Acc@1: 82.74%, Acc@5: 90.01%
[2023-08-26 13:48:13 trainLogger INFO] : epoch: 32/100, batch: 157/195, lr: 0.0771, loss 1.0333, grad_norm 1.16, Acc@1: 82.04%, Acc@5: 89.57%
[2023-08-26 13:48:16 trainLogger INFO] : epoch: 32/100, batch: 195/195, lr: 0.0768, loss 2.4349, grad_norm 1.57, Acc@1: 81.05%, Acc@5: 89.03%
[2023-08-26 13:48:16 trainLogger INFO] : EPOCH 32 training takes 0:00:15
[2023-08-26 13:48:18 trainLogger INFO] : [epoch 32] Acc@1: 67.19%, Acc@5: 88.81%, loss: 1.3610
[2023-08-26 13:48:18 trainLogger INFO] : epoch: 33/100, batch: 1/195, lr: 0.0768, loss 1.0032, grad_norm 1.04, Acc@1: 96.48%, Acc@5: 98.44%
[2023-08-26 13:48:21 trainLogger INFO] : epoch: 33/100, batch: 40/195, lr: 0.0765, loss 1.0313, grad_norm 1.21, Acc@1: 78.77%, Acc@5: 87.13%
[2023-08-26 13:48:24 trainLogger INFO] : epoch: 33/100, batch: 79/195, lr: 0.0763, loss 1.0332, grad_norm 1.26, Acc@1: 77.43%, Acc@5: 86.34%
[2023-08-26 13:48:27 trainLogger INFO] : epoch: 33/100, batch: 118/195, lr: 0.0760, loss 3.1465, grad_norm 1.88, Acc@1: 78.20%, Acc@5: 86.50%
[2023-08-26 13:48:30 trainLogger INFO] : epoch: 33/100, batch: 157/195, lr: 0.0757, loss 1.0129, grad_norm 1.13, Acc@1: 79.31%, Acc@5: 87.78%
[2023-08-26 13:48:33 trainLogger INFO] : epoch: 33/100, batch: 195/195, lr: 0.0755, loss 1.0450, grad_norm 1.25, Acc@1: 79.63%, Acc@5: 87.87%
[2023-08-26 13:48:33 trainLogger INFO] : EPOCH 33 training takes 0:00:15
[2023-08-26 13:48:35 trainLogger INFO] : [epoch 33] Acc@1: 67.44%, Acc@5: 88.69%, loss: 1.3767
[2023-08-26 13:48:36 trainLogger INFO] : epoch: 34/100, batch: 1/195, lr: 0.0755, loss 0.9750, grad_norm 1.01, Acc@1: 97.27%, Acc@5: 99.22%
[2023-08-26 13:48:39 trainLogger INFO] : epoch: 34/100, batch: 40/195, lr: 0.0752, loss 0.9567, grad_norm 0.92, Acc@1: 80.88%, Acc@5: 88.53%
[2023-08-26 13:48:42 trainLogger INFO] : epoch: 34/100, batch: 79/195, lr: 0.0749, loss 0.9949, grad_norm 1.10, Acc@1: 83.85%, Acc@5: 91.60%
[2023-08-26 13:48:45 trainLogger INFO] : epoch: 34/100, batch: 118/195, lr: 0.0746, loss 1.0142, grad_norm 1.14, Acc@1: 82.73%, Acc@5: 90.58%
[2023-08-26 13:48:48 trainLogger INFO] : epoch: 34/100, batch: 157/195, lr: 0.0744, loss 1.0241, grad_norm 1.18, Acc@1: 82.20%, Acc@5: 90.20%
[2023-08-26 13:48:51 trainLogger INFO] : epoch: 34/100, batch: 195/195, lr: 0.0741, loss 1.0117, grad_norm 1.21, Acc@1: 82.80%, Acc@5: 90.64%
[2023-08-26 13:48:51 trainLogger INFO] : EPOCH 34 training takes 0:00:15
[2023-08-26 13:48:52 trainLogger INFO] : [epoch 34] Acc@1: 67.07%, Acc@5: 89.07%, loss: 1.3630
[2023-08-26 13:48:53 trainLogger INFO] : epoch: 35/100, batch: 1/195, lr: 0.0741, loss 1.0006, grad_norm 1.08, Acc@1: 95.70%, Acc@5: 99.22%
[2023-08-26 13:48:56 trainLogger INFO] : epoch: 35/100, batch: 40/195, lr: 0.0738, loss 0.9884, grad_norm 1.05, Acc@1: 84.22%, Acc@5: 89.65%
[2023-08-26 13:48:59 trainLogger INFO] : epoch: 35/100, batch: 79/195, lr: 0.0735, loss 0.9628, grad_norm 0.96, Acc@1: 81.33%, Acc@5: 87.38%
[2023-08-26 13:49:02 trainLogger INFO] : epoch: 35/100, batch: 118/195, lr: 0.0733, loss 1.0058, grad_norm 1.17, Acc@1: 79.58%, Acc@5: 86.01%
[2023-08-26 13:49:05 trainLogger INFO] : epoch: 35/100, batch: 157/195, lr: 0.0730, loss 1.0156, grad_norm 1.13, Acc@1: 79.44%, Acc@5: 86.09%
[2023-08-26 13:49:08 trainLogger INFO] : epoch: 35/100, batch: 195/195, lr: 0.0727, loss 1.0437, grad_norm 1.32, Acc@1: 81.05%, Acc@5: 87.69%
[2023-08-26 13:49:08 trainLogger INFO] : EPOCH 35 training takes 0:00:15
[2023-08-26 13:49:10 trainLogger INFO] : [epoch 35] Acc@1: 66.78%, Acc@5: 88.73%, loss: 1.4124
[2023-08-26 13:49:10 trainLogger INFO] : epoch: 36/100, batch: 1/195, lr: 0.0727, loss 0.9890, grad_norm 1.04, Acc@1: 96.09%, Acc@5: 98.83%
[2023-08-26 13:49:13 trainLogger INFO] : epoch: 36/100, batch: 40/195, lr: 0.0724, loss 1.8036, grad_norm 1.04, Acc@1: 78.80%, Acc@5: 86.30%
[2023-08-26 13:49:16 trainLogger INFO] : epoch: 36/100, batch: 79/195, lr: 0.0721, loss 0.9841, grad_norm 1.01, Acc@1: 80.62%, Acc@5: 88.02%
[2023-08-26 13:49:19 trainLogger INFO] : epoch: 36/100, batch: 118/195, lr: 0.0719, loss 2.5696, grad_norm 1.63, Acc@1: 79.89%, Acc@5: 87.20%
[2023-08-26 13:49:22 trainLogger INFO] : epoch: 36/100, batch: 157/195, lr: 0.0716, loss 0.9666, grad_norm 0.95, Acc@1: 79.13%, Acc@5: 86.99%
[2023-08-26 13:49:25 trainLogger INFO] : epoch: 36/100, batch: 195/195, lr: 0.0713, loss 2.9708, grad_norm 1.91, Acc@1: 80.46%, Acc@5: 88.30%
[2023-08-26 13:49:25 trainLogger INFO] : EPOCH 36 training takes 0:00:15
[2023-08-26 13:49:27 trainLogger INFO] : [epoch 36] Acc@1: 67.17%, Acc@5: 88.74%, loss: 1.3831
[2023-08-26 13:49:28 trainLogger INFO] : epoch: 37/100, batch: 1/195, lr: 0.0713, loss 0.9520, grad_norm 0.94, Acc@1: 97.66%, Acc@5: 99.61%
[2023-08-26 13:49:31 trainLogger INFO] : epoch: 37/100, batch: 40/195, lr: 0.0710, loss 3.0362, grad_norm 1.90, Acc@1: 79.19%, Acc@5: 89.49%
[2023-08-26 13:49:34 trainLogger INFO] : epoch: 37/100, batch: 79/195, lr: 0.0707, loss 0.9918, grad_norm 1.14, Acc@1: 82.82%, Acc@5: 90.43%
[2023-08-26 13:49:37 trainLogger INFO] : epoch: 37/100, batch: 118/195, lr: 0.0704, loss 0.9613, grad_norm 1.14, Acc@1: 85.29%, Acc@5: 91.76%
[2023-08-26 13:49:40 trainLogger INFO] : epoch: 37/100, batch: 157/195, lr: 0.0701, loss 0.9687, grad_norm 1.07, Acc@1: 85.35%, Acc@5: 91.37%
[2023-08-26 13:49:43 trainLogger INFO] : epoch: 37/100, batch: 195/195, lr: 0.0699, loss 0.9933, grad_norm 1.20, Acc@1: 85.05%, Acc@5: 91.49%
[2023-08-26 13:49:43 trainLogger INFO] : EPOCH 37 training takes 0:00:15
[2023-08-26 13:49:44 trainLogger INFO] : [epoch 37] Acc@1: 66.74%, Acc@5: 89.05%, loss: 1.3822
[2023-08-26 13:49:45 trainLogger INFO] : epoch: 38/100, batch: 1/195, lr: 0.0699, loss 3.0019, grad_norm 1.83, Acc@1: 8.98%, Acc@5: 30.47%
[2023-08-26 13:49:48 trainLogger INFO] : epoch: 38/100, batch: 40/195, lr: 0.0696, loss 2.0806, grad_norm 1.34, Acc@1: 75.55%, Acc@5: 85.72%
[2023-08-26 13:49:51 trainLogger INFO] : epoch: 38/100, batch: 79/195, lr: 0.0693, loss 1.0151, grad_norm 1.05, Acc@1: 79.00%, Acc@5: 87.80%
[2023-08-26 13:49:54 trainLogger INFO] : epoch: 38/100, batch: 118/195, lr: 0.0690, loss 0.9698, grad_norm 1.08, Acc@1: 82.14%, Acc@5: 90.08%
[2023-08-26 13:49:57 trainLogger INFO] : epoch: 38/100, batch: 157/195, lr: 0.0687, loss 0.9819, grad_norm 1.07, Acc@1: 81.77%, Acc@5: 89.30%
[2023-08-26 13:50:00 trainLogger INFO] : epoch: 38/100, batch: 195/195, lr: 0.0684, loss 3.3277, grad_norm 2.39, Acc@1: 82.12%, Acc@5: 89.31%
[2023-08-26 13:50:00 trainLogger INFO] : EPOCH 38 training takes 0:00:15
[2023-08-26 13:50:02 trainLogger INFO] : [epoch 38] Acc@1: 67.95%, Acc@5: 89.08%, loss: 1.3732
[2023-08-26 13:50:02 trainLogger INFO] : epoch: 39/100, batch: 1/195, lr: 0.0684, loss 0.9739, grad_norm 1.01, Acc@1: 96.09%, Acc@5: 99.61%
[2023-08-26 13:50:05 trainLogger INFO] : epoch: 39/100, batch: 40/195, lr: 0.0681, loss 0.9232, grad_norm 0.90, Acc@1: 75.48%, Acc@5: 81.04%
[2023-08-26 13:50:08 trainLogger INFO] : epoch: 39/100, batch: 79/195, lr: 0.0678, loss 3.3888, grad_norm 2.60, Acc@1: 80.78%, Acc@5: 86.54%
[2023-08-26 13:50:11 trainLogger INFO] : epoch: 39/100, batch: 118/195, lr: 0.0675, loss 0.9552, grad_norm 1.04, Acc@1: 81.23%, Acc@5: 87.59%
[2023-08-26 13:50:14 trainLogger INFO] : epoch: 39/100, batch: 157/195, lr: 0.0672, loss 0.9383, grad_norm 0.95, Acc@1: 82.19%, Acc@5: 88.77%
[2023-08-26 13:50:17 trainLogger INFO] : epoch: 39/100, batch: 195/195, lr: 0.0669, loss 0.9678, grad_norm 0.96, Acc@1: 81.96%, Acc@5: 88.74%
[2023-08-26 13:50:18 trainLogger INFO] : EPOCH 39 training takes 0:00:15
[2023-08-26 13:50:19 trainLogger INFO] : [epoch 39] Acc@1: 67.97%, Acc@5: 88.69%, loss: 1.3831
[2023-08-26 13:50:20 trainLogger INFO] : epoch: 40/100, batch: 1/195, lr: 0.0669, loss 1.1575, grad_norm 1.07, Acc@1: 96.48%, Acc@5: 100.00%
[2023-08-26 13:50:23 trainLogger INFO] : epoch: 40/100, batch: 40/195, lr: 0.0666, loss 0.9556, grad_norm 1.00, Acc@1: 88.51%, Acc@5: 92.29%
[2023-08-26 13:50:26 trainLogger INFO] : epoch: 40/100, batch: 79/195, lr: 0.0663, loss 0.9689, grad_norm 1.10, Acc@1: 86.77%, Acc@5: 91.57%
[2023-08-26 13:50:29 trainLogger INFO] : epoch: 40/100, batch: 118/195, lr: 0.0660, loss 1.0347, grad_norm 1.28, Acc@1: 84.86%, Acc@5: 90.33%
[2023-08-26 13:50:32 trainLogger INFO] : epoch: 40/100, batch: 157/195, lr: 0.0657, loss 0.9495, grad_norm 1.04, Acc@1: 84.17%, Acc@5: 90.07%
[2023-08-26 13:50:35 trainLogger INFO] : epoch: 40/100, batch: 195/195, lr: 0.0655, loss 0.9914, grad_norm 1.15, Acc@1: 85.27%, Acc@5: 91.43%
[2023-08-26 13:50:35 trainLogger INFO] : EPOCH 40 training takes 0:00:15
[2023-08-26 13:50:37 trainLogger INFO] : [epoch 40] Acc@1: 66.90%, Acc@5: 88.67%, loss: 1.3935
[2023-08-26 13:50:37 trainLogger INFO] : epoch: 41/100, batch: 1/195, lr: 0.0655, loss 2.9007, grad_norm 1.87, Acc@1: 7.42%, Acc@5: 21.09%
[2023-08-26 13:50:40 trainLogger INFO] : epoch: 41/100, batch: 40/195, lr: 0.0652, loss 0.9575, grad_norm 1.00, Acc@1: 91.29%, Acc@5: 95.81%
[2023-08-26 13:50:43 trainLogger INFO] : epoch: 41/100, batch: 79/195, lr: 0.0649, loss 1.6289, grad_norm 1.05, Acc@1: 88.19%, Acc@5: 93.25%
[2023-08-26 13:50:46 trainLogger INFO] : epoch: 41/100, batch: 118/195, lr: 0.0646, loss 0.9737, grad_norm 1.03, Acc@1: 85.79%, Acc@5: 91.40%
[2023-08-26 13:50:49 trainLogger INFO] : epoch: 41/100, batch: 157/195, lr: 0.0643, loss 1.3008, grad_norm 1.45, Acc@1: 85.39%, Acc@5: 91.21%
[2023-08-26 13:50:52 trainLogger INFO] : epoch: 41/100, batch: 195/195, lr: 0.0640, loss 0.9769, grad_norm 1.02, Acc@1: 84.83%, Acc@5: 91.03%
[2023-08-26 13:50:52 trainLogger INFO] : EPOCH 41 training takes 0:00:15
[2023-08-26 13:50:54 trainLogger INFO] : [epoch 41] Acc@1: 66.82%, Acc@5: 88.21%, loss: 1.4057
[2023-08-26 13:50:55 trainLogger INFO] : epoch: 42/100, batch: 1/195, lr: 0.0639, loss 1.1634, grad_norm 1.05, Acc@1: 95.31%, Acc@5: 99.22%
[2023-08-26 13:50:58 trainLogger INFO] : epoch: 42/100, batch: 40/195, lr: 0.0636, loss 0.9268, grad_norm 0.90, Acc@1: 88.25%, Acc@5: 94.17%
[2023-08-26 13:51:01 trainLogger INFO] : epoch: 42/100, batch: 79/195, lr: 0.0633, loss 0.9294, grad_norm 0.93, Acc@1: 83.14%, Acc@5: 89.36%
[2023-08-26 13:51:04 trainLogger INFO] : epoch: 42/100, batch: 118/195, lr: 0.0630, loss 3.2369, grad_norm 2.06, Acc@1: 82.30%, Acc@5: 89.00%
[2023-08-26 13:51:07 trainLogger INFO] : epoch: 42/100, batch: 157/195, lr: 0.0627, loss 0.9643, grad_norm 1.04, Acc@1: 82.69%, Acc@5: 89.20%
[2023-08-26 13:51:10 trainLogger INFO] : epoch: 42/100, batch: 195/195, lr: 0.0624, loss 0.9504, grad_norm 0.98, Acc@1: 84.00%, Acc@5: 90.30%
[2023-08-26 13:51:10 trainLogger INFO] : EPOCH 42 training takes 0:00:15
[2023-08-26 13:51:11 trainLogger INFO] : [epoch 42] Acc@1: 68.16%, Acc@5: 89.23%, loss: 1.3473
[2023-08-26 13:51:12 trainLogger INFO] : epoch: 43/100, batch: 1/195, lr: 0.0624, loss 1.6099, grad_norm 1.31, Acc@1: 94.92%, Acc@5: 99.61%
[2023-08-26 13:51:15 trainLogger INFO] : epoch: 43/100, batch: 40/195, lr: 0.0621, loss 0.9829, grad_norm 1.18, Acc@1: 83.49%, Acc@5: 89.80%
[2023-08-26 13:51:18 trainLogger INFO] : epoch: 43/100, batch: 79/195, lr: 0.0618, loss 0.9703, grad_norm 1.03, Acc@1: 85.88%, Acc@5: 91.28%
[2023-08-26 13:51:21 trainLogger INFO] : epoch: 43/100, batch: 118/195, lr: 0.0615, loss 0.9711, grad_norm 1.08, Acc@1: 85.77%, Acc@5: 91.11%
[2023-08-26 13:51:24 trainLogger INFO] : epoch: 43/100, batch: 157/195, lr: 0.0612, loss 0.9548, grad_norm 1.14, Acc@1: 84.85%, Acc@5: 90.48%
[2023-08-26 13:51:27 trainLogger INFO] : epoch: 43/100, batch: 195/195, lr: 0.0609, loss 3.4080, grad_norm 2.96, Acc@1: 84.74%, Acc@5: 90.49%
[2023-08-26 13:51:27 trainLogger INFO] : EPOCH 43 training takes 0:00:15
[2023-08-26 13:51:29 trainLogger INFO] : [epoch 43] Acc@1: 68.49%, Acc@5: 89.77%, loss: 1.3194
[2023-08-26 13:51:29 trainLogger INFO] : epoch: 44/100, batch: 1/195, lr: 0.0609, loss 0.8994, grad_norm 0.79, Acc@1: 99.22%, Acc@5: 99.61%
[2023-08-26 13:51:32 trainLogger INFO] : epoch: 44/100, batch: 40/195, lr: 0.0606, loss 1.7658, grad_norm 1.18, Acc@1: 88.11%, Acc@5: 92.96%
[2023-08-26 13:51:36 trainLogger INFO] : epoch: 44/100, batch: 79/195, lr: 0.0603, loss 0.9185, grad_norm 0.87, Acc@1: 87.50%, Acc@5: 91.94%
[2023-08-26 13:51:39 trainLogger INFO] : epoch: 44/100, batch: 118/195, lr: 0.0600, loss 0.9199, grad_norm 0.91, Acc@1: 85.62%, Acc@5: 90.73%
[2023-08-26 13:51:42 trainLogger INFO] : epoch: 44/100, batch: 157/195, lr: 0.0597, loss 0.9796, grad_norm 1.13, Acc@1: 84.47%, Acc@5: 89.62%
[2023-08-26 13:51:44 trainLogger INFO] : epoch: 44/100, batch: 195/195, lr: 0.0594, loss 0.9702, grad_norm 1.10, Acc@1: 84.77%, Acc@5: 90.42%
[2023-08-26 13:51:45 trainLogger INFO] : EPOCH 44 training takes 0:00:15
[2023-08-26 13:51:46 trainLogger INFO] : [epoch 44] Acc@1: 67.55%, Acc@5: 88.46%, loss: 1.3736
[2023-08-26 13:51:47 trainLogger INFO] : epoch: 45/100, batch: 1/195, lr: 0.0594, loss 0.9248, grad_norm 0.86, Acc@1: 97.66%, Acc@5: 100.00%
[2023-08-26 13:51:50 trainLogger INFO] : epoch: 45/100, batch: 40/195, lr: 0.0591, loss 0.9110, grad_norm 0.84, Acc@1: 83.54%, Acc@5: 91.13%
[2023-08-26 13:51:53 trainLogger INFO] : epoch: 45/100, batch: 79/195, lr: 0.0588, loss 0.9318, grad_norm 0.96, Acc@1: 84.67%, Acc@5: 92.04%
[2023-08-26 13:51:56 trainLogger INFO] : epoch: 45/100, batch: 118/195, lr: 0.0584, loss 0.9262, grad_norm 0.97, Acc@1: 85.33%, Acc@5: 91.92%
[2023-08-26 13:51:59 trainLogger INFO] : epoch: 45/100, batch: 157/195, lr: 0.0581, loss 0.9164, grad_norm 0.89, Acc@1: 86.83%, Acc@5: 93.17%
[2023-08-26 13:52:02 trainLogger INFO] : epoch: 45/100, batch: 195/195, lr: 0.0578, loss 0.9530, grad_norm 1.04, Acc@1: 86.24%, Acc@5: 92.73%
[2023-08-26 13:52:02 trainLogger INFO] : EPOCH 45 training takes 0:00:15
[2023-08-26 13:52:04 trainLogger INFO] : [epoch 45] Acc@1: 67.19%, Acc@5: 88.35%, loss: 1.4242
[2023-08-26 13:52:04 trainLogger INFO] : epoch: 46/100, batch: 1/195, lr: 0.0578, loss 0.9199, grad_norm 0.87, Acc@1: 97.66%, Acc@5: 99.61%
[2023-08-26 13:52:07 trainLogger INFO] : epoch: 46/100, batch: 40/195, lr: 0.0575, loss 0.9273, grad_norm 1.00, Acc@1: 86.11%, Acc@5: 90.45%
[2023-08-26 13:52:10 trainLogger INFO] : epoch: 46/100, batch: 79/195, lr: 0.0572, loss 0.9200, grad_norm 0.92, Acc@1: 84.03%, Acc@5: 89.19%
[2023-08-26 13:52:13 trainLogger INFO] : epoch: 46/100, batch: 118/195, lr: 0.0569, loss 0.9384, grad_norm 0.98, Acc@1: 85.55%, Acc@5: 90.82%
[2023-08-26 13:52:16 trainLogger INFO] : epoch: 46/100, batch: 157/195, lr: 0.0566, loss 0.9330, grad_norm 0.97, Acc@1: 85.48%, Acc@5: 90.88%
[2023-08-26 13:52:19 trainLogger INFO] : epoch: 46/100, batch: 195/195, lr: 0.0563, loss 0.9233, grad_norm 0.95, Acc@1: 85.99%, Acc@5: 91.23%
[2023-08-26 13:52:19 trainLogger INFO] : EPOCH 46 training takes 0:00:15
[2023-08-26 13:52:21 trainLogger INFO] : [epoch 46] Acc@1: 69.16%, Acc@5: 89.59%, loss: 1.3271
[2023-08-26 13:52:22 trainLogger INFO] : epoch: 47/100, batch: 1/195, lr: 0.0563, loss 0.9180, grad_norm 0.88, Acc@1: 98.44%, Acc@5: 99.61%
[2023-08-26 13:52:25 trainLogger INFO] : epoch: 47/100, batch: 40/195, lr: 0.0560, loss 0.9242, grad_norm 1.00, Acc@1: 76.04%, Acc@5: 83.09%
[2023-08-26 13:52:28 trainLogger INFO] : epoch: 47/100, batch: 79/195, lr: 0.0556, loss 0.9027, grad_norm 0.91, Acc@1: 80.09%, Acc@5: 86.70%
[2023-08-26 13:52:31 trainLogger INFO] : epoch: 47/100, batch: 118/195, lr: 0.0553, loss 0.9001, grad_norm 0.84, Acc@1: 83.60%, Acc@5: 89.06%
[2023-08-26 13:52:34 trainLogger INFO] : epoch: 47/100, batch: 157/195, lr: 0.0550, loss 0.9413, grad_norm 0.97, Acc@1: 84.06%, Acc@5: 89.16%
[2023-08-26 13:52:37 trainLogger INFO] : epoch: 47/100, batch: 195/195, lr: 0.0547, loss 0.9431, grad_norm 1.02, Acc@1: 82.87%, Acc@5: 88.51%
[2023-08-26 13:52:37 trainLogger INFO] : EPOCH 47 training takes 0:00:15
[2023-08-26 13:52:38 trainLogger INFO] : [epoch 47] Acc@1: 69.01%, Acc@5: 89.65%, loss: 1.3684
[2023-08-26 13:52:39 trainLogger INFO] : epoch: 48/100, batch: 1/195, lr: 0.0547, loss 0.9193, grad_norm 0.98, Acc@1: 98.44%, Acc@5: 100.00%
[2023-08-26 13:52:42 trainLogger INFO] : epoch: 48/100, batch: 40/195, lr: 0.0544, loss 2.3917, grad_norm 1.52, Acc@1: 79.20%, Acc@5: 85.34%
[2023-08-26 13:52:45 trainLogger INFO] : epoch: 48/100, batch: 79/195, lr: 0.0541, loss 0.9294, grad_norm 1.08, Acc@1: 84.40%, Acc@5: 90.17%
[2023-08-26 13:52:48 trainLogger INFO] : epoch: 48/100, batch: 118/195, lr: 0.0538, loss 0.9844, grad_norm 1.13, Acc@1: 85.41%, Acc@5: 91.32%
[2023-08-26 13:52:51 trainLogger INFO] : epoch: 48/100, batch: 157/195, lr: 0.0535, loss 0.9023, grad_norm 0.82, Acc@1: 85.28%, Acc@5: 90.65%
[2023-08-26 13:52:54 trainLogger INFO] : epoch: 48/100, batch: 195/195, lr: 0.0531, loss 0.9297, grad_norm 0.96, Acc@1: 85.59%, Acc@5: 90.99%
[2023-08-26 13:52:54 trainLogger INFO] : EPOCH 48 training takes 0:00:15
[2023-08-26 13:52:56 trainLogger INFO] : [epoch 48] Acc@1: 68.66%, Acc@5: 89.20%, loss: 1.3534
[2023-08-26 13:52:56 trainLogger INFO] : epoch: 49/100, batch: 1/195, lr: 0.0531, loss 0.8923, grad_norm 0.81, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 13:52:59 trainLogger INFO] : epoch: 49/100, batch: 40/195, lr: 0.0528, loss 0.8821, grad_norm 0.75, Acc@1: 93.31%, Acc@5: 96.68%
[2023-08-26 13:53:02 trainLogger INFO] : epoch: 49/100, batch: 79/195, lr: 0.0525, loss 0.8802, grad_norm 0.68, Acc@1: 88.75%, Acc@5: 93.24%
[2023-08-26 13:53:06 trainLogger INFO] : epoch: 49/100, batch: 118/195, lr: 0.0522, loss 0.8920, grad_norm 0.81, Acc@1: 88.57%, Acc@5: 93.22%
[2023-08-26 13:53:09 trainLogger INFO] : epoch: 49/100, batch: 157/195, lr: 0.0519, loss 1.1649, grad_norm 1.10, Acc@1: 89.21%, Acc@5: 94.08%
[2023-08-26 13:53:12 trainLogger INFO] : epoch: 49/100, batch: 195/195, lr: 0.0516, loss 0.9217, grad_norm 1.00, Acc@1: 89.09%, Acc@5: 94.07%
[2023-08-26 13:53:12 trainLogger INFO] : EPOCH 49 training takes 0:00:15
[2023-08-26 13:53:13 trainLogger INFO] : [epoch 49] Acc@1: 68.53%, Acc@5: 89.16%, loss: 1.3511
[2023-08-26 13:53:14 trainLogger INFO] : epoch: 50/100, batch: 1/195, lr: 0.0516, loss 0.9173, grad_norm 0.88, Acc@1: 98.05%, Acc@5: 100.00%
[2023-08-26 13:53:17 trainLogger INFO] : epoch: 50/100, batch: 40/195, lr: 0.0513, loss 2.8552, grad_norm 1.97, Acc@1: 85.00%, Acc@5: 91.46%
[2023-08-26 13:53:20 trainLogger INFO] : epoch: 50/100, batch: 79/195, lr: 0.0509, loss 0.9221, grad_norm 1.01, Acc@1: 88.15%, Acc@5: 93.01%
[2023-08-26 13:53:23 trainLogger INFO] : epoch: 50/100, batch: 118/195, lr: 0.0506, loss 2.2125, grad_norm 1.66, Acc@1: 88.64%, Acc@5: 93.25%
[2023-08-26 13:53:26 trainLogger INFO] : epoch: 50/100, batch: 157/195, lr: 0.0503, loss 0.9140, grad_norm 0.95, Acc@1: 88.17%, Acc@5: 93.11%
[2023-08-26 13:53:29 trainLogger INFO] : epoch: 50/100, batch: 195/195, lr: 0.0500, loss 0.9142, grad_norm 0.91, Acc@1: 88.37%, Acc@5: 93.39%
[2023-08-26 13:53:29 trainLogger INFO] : EPOCH 50 training takes 0:00:15
[2023-08-26 13:53:31 trainLogger INFO] : [epoch 50] Acc@1: 68.64%, Acc@5: 89.27%, loss: 1.3627
[2023-08-26 13:53:31 trainLogger INFO] : epoch: 51/100, batch: 1/195, lr: 0.0500, loss 0.9246, grad_norm 0.96, Acc@1: 97.66%, Acc@5: 99.61%
[2023-08-26 13:53:34 trainLogger INFO] : epoch: 51/100, batch: 40/195, lr: 0.0497, loss 0.9160, grad_norm 0.91, Acc@1: 80.41%, Acc@5: 87.03%
[2023-08-26 13:53:37 trainLogger INFO] : epoch: 51/100, batch: 79/195, lr: 0.0494, loss 0.8959, grad_norm 0.91, Acc@1: 85.85%, Acc@5: 91.00%
[2023-08-26 13:53:40 trainLogger INFO] : epoch: 51/100, batch: 118/195, lr: 0.0491, loss 0.9144, grad_norm 0.98, Acc@1: 85.54%, Acc@5: 90.88%
[2023-08-26 13:53:43 trainLogger INFO] : epoch: 51/100, batch: 157/195, lr: 0.0487, loss 0.9082, grad_norm 0.97, Acc@1: 87.59%, Acc@5: 92.78%
[2023-08-26 13:53:46 trainLogger INFO] : epoch: 51/100, batch: 195/195, lr: 0.0484, loss 2.7195, grad_norm 2.00, Acc@1: 86.57%, Acc@5: 92.16%
[2023-08-26 13:53:46 trainLogger INFO] : EPOCH 51 training takes 0:00:15
[2023-08-26 13:53:48 trainLogger INFO] : [epoch 51] Acc@1: 68.63%, Acc@5: 88.57%, loss: 1.4204
[2023-08-26 13:53:49 trainLogger INFO] : epoch: 52/100, batch: 1/195, lr: 0.0484, loss 0.9263, grad_norm 1.05, Acc@1: 98.05%, Acc@5: 100.00%
[2023-08-26 13:53:52 trainLogger INFO] : epoch: 52/100, batch: 40/195, lr: 0.0481, loss 0.8733, grad_norm 0.72, Acc@1: 82.29%, Acc@5: 87.44%
[2023-08-26 13:53:55 trainLogger INFO] : epoch: 52/100, batch: 79/195, lr: 0.0478, loss 0.8998, grad_norm 0.84, Acc@1: 85.13%, Acc@5: 89.64%
[2023-08-26 13:53:58 trainLogger INFO] : epoch: 52/100, batch: 118/195, lr: 0.0475, loss 0.9293, grad_norm 0.99, Acc@1: 86.06%, Acc@5: 90.28%
[2023-08-26 13:54:01 trainLogger INFO] : epoch: 52/100, batch: 157/195, lr: 0.0472, loss 0.9012, grad_norm 0.90, Acc@1: 85.51%, Acc@5: 90.20%
[2023-08-26 13:54:04 trainLogger INFO] : epoch: 52/100, batch: 195/195, lr: 0.0469, loss 1.2133, grad_norm 0.88, Acc@1: 86.56%, Acc@5: 91.22%
[2023-08-26 13:54:04 trainLogger INFO] : EPOCH 52 training takes 0:00:15
[2023-08-26 13:54:05 trainLogger INFO] : [epoch 52] Acc@1: 69.36%, Acc@5: 89.15%, loss: 1.3339
[2023-08-26 13:54:06 trainLogger INFO] : epoch: 53/100, batch: 1/195, lr: 0.0469, loss 0.8753, grad_norm 0.75, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 13:54:09 trainLogger INFO] : epoch: 53/100, batch: 40/195, lr: 0.0465, loss 2.8951, grad_norm 1.92, Acc@1: 87.60%, Acc@5: 93.73%
[2023-08-26 13:54:12 trainLogger INFO] : epoch: 53/100, batch: 79/195, lr: 0.0462, loss 0.8961, grad_norm 0.93, Acc@1: 83.81%, Acc@5: 90.52%
[2023-08-26 13:54:15 trainLogger INFO] : epoch: 53/100, batch: 118/195, lr: 0.0459, loss 0.9301, grad_norm 1.05, Acc@1: 86.07%, Acc@5: 92.16%
[2023-08-26 13:54:18 trainLogger INFO] : epoch: 53/100, batch: 157/195, lr: 0.0456, loss 3.1677, grad_norm 2.22, Acc@1: 85.41%, Acc@5: 91.74%
[2023-08-26 13:54:21 trainLogger INFO] : epoch: 53/100, batch: 195/195, lr: 0.0453, loss 3.1056, grad_norm 2.51, Acc@1: 83.74%, Acc@5: 90.46%
[2023-08-26 13:54:21 trainLogger INFO] : EPOCH 53 training takes 0:00:15
[2023-08-26 13:54:23 trainLogger INFO] : [epoch 53] Acc@1: 69.25%, Acc@5: 89.09%, loss: 1.3631
[2023-08-26 13:54:23 trainLogger INFO] : epoch: 54/100, batch: 1/195, lr: 0.0453, loss 0.9157, grad_norm 0.99, Acc@1: 98.44%, Acc@5: 100.00%
[2023-08-26 13:54:27 trainLogger INFO] : epoch: 54/100, batch: 40/195, lr: 0.0450, loss 2.7941, grad_norm 1.90, Acc@1: 86.29%, Acc@5: 91.32%
[2023-08-26 13:54:30 trainLogger INFO] : epoch: 54/100, batch: 79/195, lr: 0.0447, loss 0.9099, grad_norm 0.99, Acc@1: 86.66%, Acc@5: 91.89%
[2023-08-26 13:54:33 trainLogger INFO] : epoch: 54/100, batch: 118/195, lr: 0.0444, loss 0.9079, grad_norm 0.93, Acc@1: 83.78%, Acc@5: 89.57%
[2023-08-26 13:54:36 trainLogger INFO] : epoch: 54/100, batch: 157/195, lr: 0.0440, loss 2.3106, grad_norm 1.50, Acc@1: 84.28%, Acc@5: 89.61%
[2023-08-26 13:54:39 trainLogger INFO] : epoch: 54/100, batch: 195/195, lr: 0.0437, loss 0.9366, grad_norm 1.06, Acc@1: 84.24%, Acc@5: 89.60%
[2023-08-26 13:54:39 trainLogger INFO] : EPOCH 54 training takes 0:00:15
[2023-08-26 13:54:40 trainLogger INFO] : [epoch 54] Acc@1: 68.99%, Acc@5: 89.33%, loss: 1.3352
[2023-08-26 13:54:41 trainLogger INFO] : epoch: 55/100, batch: 1/195, lr: 0.0437, loss 2.6678, grad_norm 1.90, Acc@1: 71.09%, Acc@5: 89.45%
[2023-08-26 13:54:44 trainLogger INFO] : epoch: 55/100, batch: 40/195, lr: 0.0434, loss 0.8793, grad_norm 0.77, Acc@1: 84.07%, Acc@5: 90.11%
[2023-08-26 13:54:47 trainLogger INFO] : epoch: 55/100, batch: 79/195, lr: 0.0431, loss 1.9011, grad_norm 1.24, Acc@1: 83.02%, Acc@5: 88.63%
[2023-08-26 13:54:50 trainLogger INFO] : epoch: 55/100, batch: 118/195, lr: 0.0428, loss 0.9120, grad_norm 1.00, Acc@1: 84.11%, Acc@5: 89.01%
[2023-08-26 13:54:53 trainLogger INFO] : epoch: 55/100, batch: 157/195, lr: 0.0425, loss 0.9243, grad_norm 1.08, Acc@1: 85.12%, Acc@5: 89.83%
[2023-08-26 13:54:56 trainLogger INFO] : epoch: 55/100, batch: 195/195, lr: 0.0422, loss 0.8645, grad_norm 0.65, Acc@1: 84.28%, Acc@5: 89.22%
[2023-08-26 13:54:56 trainLogger INFO] : EPOCH 55 training takes 0:00:15
[2023-08-26 13:54:58 trainLogger INFO] : [epoch 55] Acc@1: 70.06%, Acc@5: 89.35%, loss: 1.3323
[2023-08-26 13:54:58 trainLogger INFO] : epoch: 56/100, batch: 1/195, lr: 0.0422, loss 0.8513, grad_norm 0.55, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 13:55:01 trainLogger INFO] : epoch: 56/100, batch: 40/195, lr: 0.0419, loss 0.8936, grad_norm 0.91, Acc@1: 86.83%, Acc@5: 91.43%
[2023-08-26 13:55:04 trainLogger INFO] : epoch: 56/100, batch: 79/195, lr: 0.0416, loss 0.8810, grad_norm 0.74, Acc@1: 88.60%, Acc@5: 92.47%
[2023-08-26 13:55:07 trainLogger INFO] : epoch: 56/100, batch: 118/195, lr: 0.0412, loss 0.8980, grad_norm 0.86, Acc@1: 90.29%, Acc@5: 93.95%
[2023-08-26 13:55:10 trainLogger INFO] : epoch: 56/100, batch: 157/195, lr: 0.0409, loss 0.9021, grad_norm 1.02, Acc@1: 88.51%, Acc@5: 92.39%
[2023-08-26 13:55:13 trainLogger INFO] : epoch: 56/100, batch: 195/195, lr: 0.0406, loss 0.9073, grad_norm 0.97, Acc@1: 87.73%, Acc@5: 91.94%
[2023-08-26 13:55:13 trainLogger INFO] : EPOCH 56 training takes 0:00:15
[2023-08-26 13:55:15 trainLogger INFO] : [epoch 56] Acc@1: 69.03%, Acc@5: 89.12%, loss: 1.3531
[2023-08-26 13:55:16 trainLogger INFO] : epoch: 57/100, batch: 1/195, lr: 0.0406, loss 0.8686, grad_norm 0.71, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 13:55:19 trainLogger INFO] : epoch: 57/100, batch: 40/195, lr: 0.0403, loss 0.8911, grad_norm 0.90, Acc@1: 86.64%, Acc@5: 89.84%
[2023-08-26 13:55:22 trainLogger INFO] : epoch: 57/100, batch: 79/195, lr: 0.0400, loss 2.9727, grad_norm 2.11, Acc@1: 85.77%, Acc@5: 90.44%
[2023-08-26 13:55:25 trainLogger INFO] : epoch: 57/100, batch: 118/195, lr: 0.0397, loss 1.1669, grad_norm 1.07, Acc@1: 87.25%, Acc@5: 92.16%
[2023-08-26 13:55:28 trainLogger INFO] : epoch: 57/100, batch: 157/195, lr: 0.0394, loss 0.8856, grad_norm 0.90, Acc@1: 87.87%, Acc@5: 92.66%
[2023-08-26 13:55:31 trainLogger INFO] : epoch: 57/100, batch: 195/195, lr: 0.0391, loss 0.8833, grad_norm 0.82, Acc@1: 86.75%, Acc@5: 91.75%
[2023-08-26 13:55:31 trainLogger INFO] : EPOCH 57 training takes 0:00:15
[2023-08-26 13:55:32 trainLogger INFO] : [epoch 57] Acc@1: 69.52%, Acc@5: 89.24%, loss: 1.3625
[2023-08-26 13:55:33 trainLogger INFO] : epoch: 58/100, batch: 1/195, lr: 0.0391, loss 2.1107, grad_norm 1.70, Acc@1: 87.89%, Acc@5: 99.22%
[2023-08-26 13:55:36 trainLogger INFO] : epoch: 58/100, batch: 40/195, lr: 0.0388, loss 0.8934, grad_norm 0.82, Acc@1: 89.85%, Acc@5: 95.68%
[2023-08-26 13:55:39 trainLogger INFO] : epoch: 58/100, batch: 79/195, lr: 0.0385, loss 2.0396, grad_norm 1.33, Acc@1: 83.08%, Acc@5: 88.62%
[2023-08-26 13:55:42 trainLogger INFO] : epoch: 58/100, batch: 118/195, lr: 0.0382, loss 0.8866, grad_norm 0.79, Acc@1: 85.08%, Acc@5: 90.64%
[2023-08-26 13:55:45 trainLogger INFO] : epoch: 58/100, batch: 157/195, lr: 0.0379, loss 2.4815, grad_norm 1.80, Acc@1: 82.21%, Acc@5: 88.18%
[2023-08-26 13:55:48 trainLogger INFO] : epoch: 58/100, batch: 195/195, lr: 0.0376, loss 0.8768, grad_norm 0.75, Acc@1: 83.89%, Acc@5: 89.45%
[2023-08-26 13:55:48 trainLogger INFO] : EPOCH 58 training takes 0:00:15
[2023-08-26 13:55:50 trainLogger INFO] : [epoch 58] Acc@1: 69.59%, Acc@5: 89.96%, loss: 1.3208
[2023-08-26 13:55:50 trainLogger INFO] : epoch: 59/100, batch: 1/195, lr: 0.0376, loss 0.9383, grad_norm 1.12, Acc@1: 96.88%, Acc@5: 99.22%
[2023-08-26 13:55:54 trainLogger INFO] : epoch: 59/100, batch: 40/195, lr: 0.0373, loss 2.6549, grad_norm 2.08, Acc@1: 87.23%, Acc@5: 94.32%
[2023-08-26 13:55:57 trainLogger INFO] : epoch: 59/100, batch: 79/195, lr: 0.0370, loss 1.7697, grad_norm 1.35, Acc@1: 87.24%, Acc@5: 93.54%
[2023-08-26 13:56:00 trainLogger INFO] : epoch: 59/100, batch: 118/195, lr: 0.0367, loss 0.8839, grad_norm 0.82, Acc@1: 87.85%, Acc@5: 93.68%
[2023-08-26 13:56:03 trainLogger INFO] : epoch: 59/100, batch: 157/195, lr: 0.0364, loss 0.8703, grad_norm 0.73, Acc@1: 88.70%, Acc@5: 94.09%
[2023-08-26 13:56:06 trainLogger INFO] : epoch: 59/100, batch: 195/195, lr: 0.0361, loss 2.2568, grad_norm 1.77, Acc@1: 87.03%, Acc@5: 92.79%
[2023-08-26 13:56:06 trainLogger INFO] : EPOCH 59 training takes 0:00:15
[2023-08-26 13:56:07 trainLogger INFO] : [epoch 59] Acc@1: 69.44%, Acc@5: 89.74%, loss: 1.3666
[2023-08-26 13:56:08 trainLogger INFO] : epoch: 60/100, batch: 1/195, lr: 0.0361, loss 0.8806, grad_norm 0.82, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 13:56:11 trainLogger INFO] : epoch: 60/100, batch: 40/195, lr: 0.0357, loss 0.8879, grad_norm 0.85, Acc@1: 88.50%, Acc@5: 92.51%
[2023-08-26 13:56:14 trainLogger INFO] : epoch: 60/100, batch: 79/195, lr: 0.0354, loss 3.2191, grad_norm 2.27, Acc@1: 87.88%, Acc@5: 93.15%
[2023-08-26 13:56:17 trainLogger INFO] : epoch: 60/100, batch: 118/195, lr: 0.0351, loss 0.8905, grad_norm 0.94, Acc@1: 86.76%, Acc@5: 92.29%
[2023-08-26 13:56:20 trainLogger INFO] : epoch: 60/100, batch: 157/195, lr: 0.0348, loss 3.2578, grad_norm 2.67, Acc@1: 85.72%, Acc@5: 91.56%
[2023-08-26 13:56:23 trainLogger INFO] : epoch: 60/100, batch: 195/195, lr: 0.0346, loss 0.8779, grad_norm 0.83, Acc@1: 84.26%, Acc@5: 90.11%
[2023-08-26 13:56:23 trainLogger INFO] : EPOCH 60 training takes 0:00:15
[2023-08-26 13:56:25 trainLogger INFO] : [epoch 60] Acc@1: 68.66%, Acc@5: 89.06%, loss: 1.3989
[2023-08-26 13:56:25 trainLogger INFO] : epoch: 61/100, batch: 1/195, lr: 0.0345, loss 0.8772, grad_norm 0.77, Acc@1: 99.22%, Acc@5: 99.61%
[2023-08-26 13:56:28 trainLogger INFO] : epoch: 61/100, batch: 40/195, lr: 0.0343, loss 0.8800, grad_norm 0.76, Acc@1: 84.04%, Acc@5: 89.19%
[2023-08-26 13:56:31 trainLogger INFO] : epoch: 61/100, batch: 79/195, lr: 0.0340, loss 0.8763, grad_norm 0.84, Acc@1: 86.38%, Acc@5: 91.03%
[2023-08-26 13:56:34 trainLogger INFO] : epoch: 61/100, batch: 118/195, lr: 0.0337, loss 0.8553, grad_norm 0.69, Acc@1: 87.61%, Acc@5: 92.31%
[2023-08-26 13:56:37 trainLogger INFO] : epoch: 61/100, batch: 157/195, lr: 0.0334, loss 0.8854, grad_norm 0.86, Acc@1: 86.50%, Acc@5: 91.58%
[2023-08-26 13:56:40 trainLogger INFO] : epoch: 61/100, batch: 195/195, lr: 0.0331, loss 0.8763, grad_norm 0.84, Acc@1: 87.32%, Acc@5: 91.91%
[2023-08-26 13:56:40 trainLogger INFO] : EPOCH 61 training takes 0:00:15
[2023-08-26 13:56:42 trainLogger INFO] : [epoch 61] Acc@1: 69.93%, Acc@5: 89.84%, loss: 1.3077
[2023-08-26 13:56:43 trainLogger INFO] : epoch: 62/100, batch: 1/195, lr: 0.0331, loss 0.9055, grad_norm 0.94, Acc@1: 98.05%, Acc@5: 99.22%
[2023-08-26 13:56:46 trainLogger INFO] : epoch: 62/100, batch: 40/195, lr: 0.0328, loss 0.9167, grad_norm 1.12, Acc@1: 91.06%, Acc@5: 96.43%
[2023-08-26 13:56:49 trainLogger INFO] : epoch: 62/100, batch: 79/195, lr: 0.0325, loss 0.9009, grad_norm 0.93, Acc@1: 91.14%, Acc@5: 96.08%
[2023-08-26 13:56:52 trainLogger INFO] : epoch: 62/100, batch: 118/195, lr: 0.0322, loss 0.8507, grad_norm 0.65, Acc@1: 86.25%, Acc@5: 91.45%
[2023-08-26 13:56:55 trainLogger INFO] : epoch: 62/100, batch: 157/195, lr: 0.0319, loss 0.8744, grad_norm 0.80, Acc@1: 84.65%, Acc@5: 90.32%
[2023-08-26 13:56:58 trainLogger INFO] : epoch: 62/100, batch: 195/195, lr: 0.0316, loss 0.8613, grad_norm 0.72, Acc@1: 85.96%, Acc@5: 91.50%
[2023-08-26 13:56:58 trainLogger INFO] : EPOCH 62 training takes 0:00:15
[2023-08-26 13:56:59 trainLogger INFO] : [epoch 62] Acc@1: 69.34%, Acc@5: 89.87%, loss: 1.3322
[2023-08-26 13:57:00 trainLogger INFO] : epoch: 63/100, batch: 1/195, lr: 0.0316, loss 0.8741, grad_norm 0.85, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 13:57:03 trainLogger INFO] : epoch: 63/100, batch: 40/195, lr: 0.0313, loss 0.9032, grad_norm 0.93, Acc@1: 83.69%, Acc@5: 88.92%
[2023-08-26 13:57:06 trainLogger INFO] : epoch: 63/100, batch: 79/195, lr: 0.0310, loss 1.9186, grad_norm 1.45, Acc@1: 86.75%, Acc@5: 92.54%
[2023-08-26 13:57:09 trainLogger INFO] : epoch: 63/100, batch: 118/195, lr: 0.0307, loss 2.6164, grad_norm 1.92, Acc@1: 86.69%, Acc@5: 92.29%
[2023-08-26 13:57:12 trainLogger INFO] : epoch: 63/100, batch: 157/195, lr: 0.0304, loss 0.8578, grad_norm 0.69, Acc@1: 87.25%, Acc@5: 92.83%
[2023-08-26 13:57:15 trainLogger INFO] : epoch: 63/100, batch: 195/195, lr: 0.0301, loss 0.8960, grad_norm 0.83, Acc@1: 84.97%, Acc@5: 90.49%
[2023-08-26 13:57:15 trainLogger INFO] : EPOCH 63 training takes 0:00:15
[2023-08-26 13:57:17 trainLogger INFO] : [epoch 63] Acc@1: 70.13%, Acc@5: 89.69%, loss: 1.3511
[2023-08-26 13:57:18 trainLogger INFO] : epoch: 64/100, batch: 1/195, lr: 0.0301, loss 0.8528, grad_norm 0.65, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 13:57:21 trainLogger INFO] : epoch: 64/100, batch: 40/195, lr: 0.0299, loss 0.8869, grad_norm 0.90, Acc@1: 92.61%, Acc@5: 95.21%
[2023-08-26 13:57:24 trainLogger INFO] : epoch: 64/100, batch: 79/195, lr: 0.0296, loss 0.8858, grad_norm 0.90, Acc@1: 88.65%, Acc@5: 93.28%
[2023-08-26 13:57:27 trainLogger INFO] : epoch: 64/100, batch: 118/195, lr: 0.0293, loss 0.9113, grad_norm 0.50, Acc@1: 87.29%, Acc@5: 91.73%
[2023-08-26 13:57:30 trainLogger INFO] : epoch: 64/100, batch: 157/195, lr: 0.0290, loss 0.8754, grad_norm 0.88, Acc@1: 86.34%, Acc@5: 91.02%
[2023-08-26 13:57:33 trainLogger INFO] : epoch: 64/100, batch: 195/195, lr: 0.0287, loss 0.8826, grad_norm 0.88, Acc@1: 86.29%, Acc@5: 90.98%
[2023-08-26 13:57:33 trainLogger INFO] : EPOCH 64 training takes 0:00:15
[2023-08-26 13:57:34 trainLogger INFO] : [epoch 64] Acc@1: 70.18%, Acc@5: 90.18%, loss: 1.3288
[2023-08-26 13:57:35 trainLogger INFO] : epoch: 65/100, batch: 1/195, lr: 0.0287, loss 0.8365, grad_norm 0.52, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 13:57:38 trainLogger INFO] : epoch: 65/100, batch: 40/195, lr: 0.0284, loss 0.8894, grad_norm 1.00, Acc@1: 86.51%, Acc@5: 91.82%
[2023-08-26 13:57:41 trainLogger INFO] : epoch: 65/100, batch: 79/195, lr: 0.0281, loss 1.3043, grad_norm 0.76, Acc@1: 87.01%, Acc@5: 92.51%
[2023-08-26 13:57:44 trainLogger INFO] : epoch: 65/100, batch: 118/195, lr: 0.0279, loss 0.8884, grad_norm 0.91, Acc@1: 89.89%, Acc@5: 94.68%
[2023-08-26 13:57:47 trainLogger INFO] : epoch: 65/100, batch: 157/195, lr: 0.0276, loss 0.8761, grad_norm 0.87, Acc@1: 88.95%, Acc@5: 94.23%
[2023-08-26 13:57:50 trainLogger INFO] : epoch: 65/100, batch: 195/195, lr: 0.0273, loss 0.8928, grad_norm 1.02, Acc@1: 87.48%, Acc@5: 92.53%
[2023-08-26 13:57:50 trainLogger INFO] : EPOCH 65 training takes 0:00:15
[2023-08-26 13:57:52 trainLogger INFO] : [epoch 65] Acc@1: 69.66%, Acc@5: 89.24%, loss: 1.4034
[2023-08-26 13:57:52 trainLogger INFO] : epoch: 66/100, batch: 1/195, lr: 0.0273, loss 2.7842, grad_norm 2.05, Acc@1: 16.02%, Acc@5: 60.55%
[2023-08-26 13:57:55 trainLogger INFO] : epoch: 66/100, batch: 40/195, lr: 0.0270, loss 0.8676, grad_norm 0.80, Acc@1: 80.55%, Acc@5: 85.47%
[2023-08-26 13:57:58 trainLogger INFO] : epoch: 66/100, batch: 79/195, lr: 0.0267, loss 0.9164, grad_norm 1.00, Acc@1: 85.21%, Acc@5: 89.77%
[2023-08-26 13:58:02 trainLogger INFO] : epoch: 66/100, batch: 118/195, lr: 0.0265, loss 0.8537, grad_norm 0.71, Acc@1: 88.47%, Acc@5: 92.14%
[2023-08-26 13:58:05 trainLogger INFO] : epoch: 66/100, batch: 157/195, lr: 0.0262, loss 0.8528, grad_norm 0.65, Acc@1: 89.43%, Acc@5: 93.23%
[2023-08-26 13:58:07 trainLogger INFO] : epoch: 66/100, batch: 195/195, lr: 0.0259, loss 2.6973, grad_norm 2.14, Acc@1: 88.74%, Acc@5: 92.65%
[2023-08-26 13:58:08 trainLogger INFO] : EPOCH 66 training takes 0:00:15
[2023-08-26 13:58:09 trainLogger INFO] : [epoch 66] Acc@1: 70.06%, Acc@5: 89.70%, loss: 1.3505
[2023-08-26 13:58:10 trainLogger INFO] : epoch: 67/100, batch: 1/195, lr: 0.0259, loss 0.8722, grad_norm 0.84, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 13:58:13 trainLogger INFO] : epoch: 67/100, batch: 40/195, lr: 0.0256, loss 0.8541, grad_norm 0.69, Acc@1: 86.52%, Acc@5: 90.55%
[2023-08-26 13:58:16 trainLogger INFO] : epoch: 67/100, batch: 79/195, lr: 0.0254, loss 2.4038, grad_norm 1.64, Acc@1: 81.51%, Acc@5: 88.00%
[2023-08-26 13:58:19 trainLogger INFO] : epoch: 67/100, batch: 118/195, lr: 0.0251, loss 0.8731, grad_norm 0.86, Acc@1: 82.13%, Acc@5: 88.17%
[2023-08-26 13:58:22 trainLogger INFO] : epoch: 67/100, batch: 157/195, lr: 0.0248, loss 0.8745, grad_norm 0.84, Acc@1: 83.08%, Acc@5: 89.10%
[2023-08-26 13:58:25 trainLogger INFO] : epoch: 67/100, batch: 195/195, lr: 0.0246, loss 0.8647, grad_norm 0.79, Acc@1: 83.12%, Acc@5: 89.16%
[2023-08-26 13:58:25 trainLogger INFO] : EPOCH 67 training takes 0:00:15
[2023-08-26 13:58:27 trainLogger INFO] : [epoch 67] Acc@1: 70.03%, Acc@5: 89.69%, loss: 1.3572
[2023-08-26 13:58:27 trainLogger INFO] : epoch: 68/100, batch: 1/195, lr: 0.0245, loss 0.8783, grad_norm 0.84, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 13:58:30 trainLogger INFO] : epoch: 68/100, batch: 40/195, lr: 0.0243, loss 2.7105, grad_norm 1.88, Acc@1: 90.48%, Acc@5: 94.79%
[2023-08-26 13:58:33 trainLogger INFO] : epoch: 68/100, batch: 79/195, lr: 0.0240, loss 0.8439, grad_norm 0.73, Acc@1: 88.17%, Acc@5: 92.28%
[2023-08-26 13:58:36 trainLogger INFO] : epoch: 68/100, batch: 118/195, lr: 0.0237, loss 0.8651, grad_norm 0.85, Acc@1: 91.12%, Acc@5: 94.62%
[2023-08-26 13:58:39 trainLogger INFO] : epoch: 68/100, batch: 157/195, lr: 0.0235, loss 0.8481, grad_norm 0.69, Acc@1: 90.26%, Acc@5: 93.55%
[2023-08-26 13:58:42 trainLogger INFO] : epoch: 68/100, batch: 195/195, lr: 0.0232, loss 2.3090, grad_norm 1.95, Acc@1: 90.00%, Acc@5: 93.26%
[2023-08-26 13:58:42 trainLogger INFO] : EPOCH 68 training takes 0:00:15
[2023-08-26 13:58:44 trainLogger INFO] : [epoch 68] Acc@1: 70.56%, Acc@5: 89.90%, loss: 1.3508
[2023-08-26 13:58:45 trainLogger INFO] : epoch: 69/100, batch: 1/195, lr: 0.0232, loss 0.8620, grad_norm 0.69, Acc@1: 98.83%, Acc@5: 99.22%
[2023-08-26 13:58:48 trainLogger INFO] : epoch: 69/100, batch: 40/195, lr: 0.0229, loss 1.9821, grad_norm 1.46, Acc@1: 88.14%, Acc@5: 91.84%
[2023-08-26 13:58:51 trainLogger INFO] : epoch: 69/100, batch: 79/195, lr: 0.0227, loss 0.8747, grad_norm 0.87, Acc@1: 87.70%, Acc@5: 91.13%
[2023-08-26 13:58:54 trainLogger INFO] : epoch: 69/100, batch: 118/195, lr: 0.0224, loss 2.1288, grad_norm 1.72, Acc@1: 87.02%, Acc@5: 91.45%
[2023-08-26 13:58:57 trainLogger INFO] : epoch: 69/100, batch: 157/195, lr: 0.0222, loss 0.8414, grad_norm 0.56, Acc@1: 87.57%, Acc@5: 91.88%
[2023-08-26 13:59:00 trainLogger INFO] : epoch: 69/100, batch: 195/195, lr: 0.0219, loss 2.6395, grad_norm 2.06, Acc@1: 86.80%, Acc@5: 91.39%
[2023-08-26 13:59:00 trainLogger INFO] : EPOCH 69 training takes 0:00:15
[2023-08-26 13:59:01 trainLogger INFO] : [epoch 69] Acc@1: 70.10%, Acc@5: 89.57%, loss: 1.3784
[2023-08-26 13:59:02 trainLogger INFO] : epoch: 70/100, batch: 1/195, lr: 0.0219, loss 0.8451, grad_norm 0.63, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 13:59:05 trainLogger INFO] : epoch: 70/100, batch: 40/195, lr: 0.0216, loss 0.8638, grad_norm 0.88, Acc@1: 86.09%, Acc@5: 90.39%
[2023-08-26 13:59:08 trainLogger INFO] : epoch: 70/100, batch: 79/195, lr: 0.0214, loss 2.6777, grad_norm 2.03, Acc@1: 86.37%, Acc@5: 90.43%
[2023-08-26 13:59:11 trainLogger INFO] : epoch: 70/100, batch: 118/195, lr: 0.0211, loss 0.8458, grad_norm 0.68, Acc@1: 84.73%, Acc@5: 89.45%
[2023-08-26 13:59:14 trainLogger INFO] : epoch: 70/100, batch: 157/195, lr: 0.0209, loss 0.8528, grad_norm 0.78, Acc@1: 85.52%, Acc@5: 90.54%
[2023-08-26 13:59:17 trainLogger INFO] : epoch: 70/100, batch: 195/195, lr: 0.0206, loss 0.8702, grad_norm 0.79, Acc@1: 86.87%, Acc@5: 91.57%
[2023-08-26 13:59:17 trainLogger INFO] : EPOCH 70 training takes 0:00:15
[2023-08-26 13:59:18 trainLogger INFO] : [epoch 70] Acc@1: 70.32%, Acc@5: 89.80%, loss: 1.3361
[2023-08-26 13:59:19 trainLogger INFO] : epoch: 71/100, batch: 1/195, lr: 0.0206, loss 1.6971, grad_norm 1.05, Acc@1: 0.00%, Acc@5: 7.42%
[2023-08-26 13:59:22 trainLogger INFO] : epoch: 71/100, batch: 40/195, lr: 0.0204, loss 1.1817, grad_norm 0.69, Acc@1: 84.86%, Acc@5: 88.91%
[2023-08-26 13:59:25 trainLogger INFO] : epoch: 71/100, batch: 79/195, lr: 0.0201, loss 2.8424, grad_norm 2.09, Acc@1: 84.49%, Acc@5: 89.81%
[2023-08-26 13:59:28 trainLogger INFO] : epoch: 71/100, batch: 118/195, lr: 0.0199, loss 0.8407, grad_norm 0.59, Acc@1: 82.34%, Acc@5: 87.49%
[2023-08-26 13:59:31 trainLogger INFO] : epoch: 71/100, batch: 157/195, lr: 0.0196, loss 0.8564, grad_norm 0.80, Acc@1: 83.28%, Acc@5: 88.36%
[2023-08-26 13:59:34 trainLogger INFO] : epoch: 71/100, batch: 195/195, lr: 0.0194, loss 0.8522, grad_norm 0.71, Acc@1: 85.10%, Acc@5: 89.79%
[2023-08-26 13:59:34 trainLogger INFO] : EPOCH 71 training takes 0:00:15
[2023-08-26 13:59:36 trainLogger INFO] : [epoch 71] Acc@1: 70.85%, Acc@5: 90.03%, loss: 1.3385
[2023-08-26 13:59:36 trainLogger INFO] : epoch: 72/100, batch: 1/195, lr: 0.0194, loss 1.0339, grad_norm 0.65, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 13:59:39 trainLogger INFO] : epoch: 72/100, batch: 40/195, lr: 0.0191, loss 0.8457, grad_norm 0.64, Acc@1: 85.92%, Acc@5: 92.24%
[2023-08-26 13:59:42 trainLogger INFO] : epoch: 72/100, batch: 79/195, lr: 0.0189, loss 2.8542, grad_norm 2.11, Acc@1: 86.00%, Acc@5: 91.68%
[2023-08-26 13:59:45 trainLogger INFO] : epoch: 72/100, batch: 118/195, lr: 0.0186, loss 2.2109, grad_norm 2.05, Acc@1: 88.39%, Acc@5: 93.47%
[2023-08-26 13:59:48 trainLogger INFO] : epoch: 72/100, batch: 157/195, lr: 0.0184, loss 0.8326, grad_norm 0.52, Acc@1: 88.05%, Acc@5: 92.95%
[2023-08-26 13:59:51 trainLogger INFO] : epoch: 72/100, batch: 195/195, lr: 0.0181, loss 0.8432, grad_norm 0.72, Acc@1: 87.96%, Acc@5: 92.77%
[2023-08-26 13:59:51 trainLogger INFO] : EPOCH 72 training takes 0:00:15
[2023-08-26 13:59:53 trainLogger INFO] : [epoch 72] Acc@1: 70.84%, Acc@5: 90.08%, loss: 1.3334
[2023-08-26 13:59:54 trainLogger INFO] : epoch: 73/100, batch: 1/195, lr: 0.0181, loss 0.8258, grad_norm 0.41, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 13:59:57 trainLogger INFO] : epoch: 73/100, batch: 40/195, lr: 0.0179, loss 0.8398, grad_norm 0.59, Acc@1: 86.61%, Acc@5: 90.84%
[2023-08-26 14:00:00 trainLogger INFO] : epoch: 73/100, batch: 79/195, lr: 0.0176, loss 0.8596, grad_norm 0.81, Acc@1: 85.45%, Acc@5: 89.89%
[2023-08-26 14:00:03 trainLogger INFO] : epoch: 73/100, batch: 118/195, lr: 0.0174, loss 0.8562, grad_norm 0.73, Acc@1: 84.17%, Acc@5: 89.66%
[2023-08-26 14:00:06 trainLogger INFO] : epoch: 73/100, batch: 157/195, lr: 0.0172, loss 2.4101, grad_norm 1.96, Acc@1: 85.03%, Acc@5: 90.82%
[2023-08-26 14:00:09 trainLogger INFO] : epoch: 73/100, batch: 195/195, lr: 0.0169, loss 0.8412, grad_norm 0.59, Acc@1: 86.30%, Acc@5: 91.69%
[2023-08-26 14:00:09 trainLogger INFO] : EPOCH 73 training takes 0:00:15
[2023-08-26 14:00:10 trainLogger INFO] : [epoch 73] Acc@1: 70.69%, Acc@5: 90.33%, loss: 1.3142
[2023-08-26 14:00:11 trainLogger INFO] : epoch: 74/100, batch: 1/195, lr: 0.0169, loss 2.5925, grad_norm 2.01, Acc@1: 75.00%, Acc@5: 92.97%
[2023-08-26 14:00:14 trainLogger INFO] : epoch: 74/100, batch: 40/195, lr: 0.0167, loss 2.0269, grad_norm 1.50, Acc@1: 79.06%, Acc@5: 85.88%
[2023-08-26 14:00:17 trainLogger INFO] : epoch: 74/100, batch: 79/195, lr: 0.0165, loss 1.6056, grad_norm 1.10, Acc@1: 81.01%, Acc@5: 86.03%
[2023-08-26 14:00:20 trainLogger INFO] : epoch: 74/100, batch: 118/195, lr: 0.0162, loss 0.8450, grad_norm 0.68, Acc@1: 83.02%, Acc@5: 87.77%
[2023-08-26 14:00:23 trainLogger INFO] : epoch: 74/100, batch: 157/195, lr: 0.0160, loss 0.8484, grad_norm 0.72, Acc@1: 85.62%, Acc@5: 89.66%
[2023-08-26 14:00:26 trainLogger INFO] : epoch: 74/100, batch: 195/195, lr: 0.0158, loss 2.0656, grad_norm 1.42, Acc@1: 86.16%, Acc@5: 90.10%
[2023-08-26 14:00:26 trainLogger INFO] : EPOCH 74 training takes 0:00:15
[2023-08-26 14:00:28 trainLogger INFO] : [epoch 74] Acc@1: 70.79%, Acc@5: 89.87%, loss: 1.3399
[2023-08-26 14:00:28 trainLogger INFO] : epoch: 75/100, batch: 1/195, lr: 0.0158, loss 2.7254, grad_norm 2.16, Acc@1: 62.11%, Acc@5: 86.33%
[2023-08-26 14:00:31 trainLogger INFO] : epoch: 75/100, batch: 40/195, lr: 0.0155, loss 0.8247, grad_norm 0.44, Acc@1: 91.72%, Acc@5: 94.43%
[2023-08-26 14:00:34 trainLogger INFO] : epoch: 75/100, batch: 79/195, lr: 0.0153, loss 0.8507, grad_norm 0.75, Acc@1: 92.04%, Acc@5: 94.89%
[2023-08-26 14:00:37 trainLogger INFO] : epoch: 75/100, batch: 118/195, lr: 0.0151, loss 0.8430, grad_norm 0.67, Acc@1: 88.85%, Acc@5: 92.15%
[2023-08-26 14:00:40 trainLogger INFO] : epoch: 75/100, batch: 157/195, lr: 0.0149, loss 2.6888, grad_norm 1.94, Acc@1: 86.73%, Acc@5: 90.38%
[2023-08-26 14:00:43 trainLogger INFO] : epoch: 75/100, batch: 195/195, lr: 0.0147, loss 0.8550, grad_norm 0.87, Acc@1: 86.28%, Acc@5: 90.08%
[2023-08-26 14:00:43 trainLogger INFO] : EPOCH 75 training takes 0:00:15
[2023-08-26 14:00:45 trainLogger INFO] : [epoch 75] Acc@1: 70.42%, Acc@5: 89.86%, loss: 1.3825
[2023-08-26 14:00:45 trainLogger INFO] : epoch: 76/100, batch: 1/195, lr: 0.0146, loss 0.8369, grad_norm 0.63, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:00:48 trainLogger INFO] : epoch: 76/100, batch: 40/195, lr: 0.0144, loss 0.8427, grad_norm 0.63, Acc@1: 84.34%, Acc@5: 91.55%
[2023-08-26 14:00:52 trainLogger INFO] : epoch: 76/100, batch: 79/195, lr: 0.0142, loss 0.8616, grad_norm 0.84, Acc@1: 84.46%, Acc@5: 90.42%
[2023-08-26 14:00:55 trainLogger INFO] : epoch: 76/100, batch: 118/195, lr: 0.0140, loss 0.8399, grad_norm 0.67, Acc@1: 85.04%, Acc@5: 90.49%
[2023-08-26 14:00:58 trainLogger INFO] : epoch: 76/100, batch: 157/195, lr: 0.0138, loss 0.8426, grad_norm 0.64, Acc@1: 86.21%, Acc@5: 91.76%
[2023-08-26 14:01:00 trainLogger INFO] : epoch: 76/100, batch: 195/195, lr: 0.0136, loss 0.8309, grad_norm 0.52, Acc@1: 87.24%, Acc@5: 92.32%
[2023-08-26 14:01:01 trainLogger INFO] : EPOCH 76 training takes 0:00:15
[2023-08-26 14:01:02 trainLogger INFO] : [epoch 76] Acc@1: 70.80%, Acc@5: 89.99%, loss: 1.3234
[2023-08-26 14:01:03 trainLogger INFO] : epoch: 77/100, batch: 1/195, lr: 0.0136, loss 0.8484, grad_norm 0.73, Acc@1: 99.22%, Acc@5: 99.61%
[2023-08-26 14:01:06 trainLogger INFO] : epoch: 77/100, batch: 40/195, lr: 0.0133, loss 0.8341, grad_norm 0.68, Acc@1: 95.08%, Acc@5: 97.42%
[2023-08-26 14:01:09 trainLogger INFO] : epoch: 77/100, batch: 79/195, lr: 0.0131, loss 0.8404, grad_norm 0.75, Acc@1: 91.68%, Acc@5: 94.92%
[2023-08-26 14:01:12 trainLogger INFO] : epoch: 77/100, batch: 118/195, lr: 0.0129, loss 1.9314, grad_norm 1.35, Acc@1: 88.69%, Acc@5: 92.49%
[2023-08-26 14:01:15 trainLogger INFO] : epoch: 77/100, batch: 157/195, lr: 0.0127, loss 0.8368, grad_norm 0.58, Acc@1: 88.57%, Acc@5: 92.88%
[2023-08-26 14:01:18 trainLogger INFO] : epoch: 77/100, batch: 195/195, lr: 0.0125, loss 0.8299, grad_norm 0.52, Acc@1: 88.19%, Acc@5: 92.30%
[2023-08-26 14:01:18 trainLogger INFO] : EPOCH 77 training takes 0:00:15
[2023-08-26 14:01:20 trainLogger INFO] : [epoch 77] Acc@1: 70.97%, Acc@5: 90.15%, loss: 1.3243
[2023-08-26 14:01:20 trainLogger INFO] : epoch: 78/100, batch: 1/195, lr: 0.0125, loss 0.8322, grad_norm 0.56, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:01:23 trainLogger INFO] : epoch: 78/100, batch: 40/195, lr: 0.0123, loss 0.8207, grad_norm 0.39, Acc@1: 81.35%, Acc@5: 86.46%
[2023-08-26 14:01:26 trainLogger INFO] : epoch: 78/100, batch: 79/195, lr: 0.0121, loss 0.8217, grad_norm 0.40, Acc@1: 84.63%, Acc@5: 89.47%
[2023-08-26 14:01:29 trainLogger INFO] : epoch: 78/100, batch: 118/195, lr: 0.0119, loss 0.8313, grad_norm 0.56, Acc@1: 88.22%, Acc@5: 92.14%
[2023-08-26 14:01:32 trainLogger INFO] : epoch: 78/100, batch: 157/195, lr: 0.0117, loss 0.8401, grad_norm 0.67, Acc@1: 87.51%, Acc@5: 91.51%
[2023-08-26 14:01:35 trainLogger INFO] : epoch: 78/100, batch: 195/195, lr: 0.0115, loss 0.8412, grad_norm 0.75, Acc@1: 87.88%, Acc@5: 91.97%
[2023-08-26 14:01:35 trainLogger INFO] : EPOCH 78 training takes 0:00:15
[2023-08-26 14:01:37 trainLogger INFO] : [epoch 78] Acc@1: 70.88%, Acc@5: 90.20%, loss: 1.3211
[2023-08-26 14:01:38 trainLogger INFO] : epoch: 79/100, batch: 1/195, lr: 0.0115, loss 0.8516, grad_norm 0.68, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:01:41 trainLogger INFO] : epoch: 79/100, batch: 40/195, lr: 0.0113, loss 0.8283, grad_norm 0.63, Acc@1: 92.40%, Acc@5: 94.69%
[2023-08-26 14:01:44 trainLogger INFO] : epoch: 79/100, batch: 79/195, lr: 0.0111, loss 0.8316, grad_norm 0.59, Acc@1: 89.86%, Acc@5: 92.99%
[2023-08-26 14:01:47 trainLogger INFO] : epoch: 79/100, batch: 118/195, lr: 0.0109, loss 0.8561, grad_norm 0.55, Acc@1: 89.64%, Acc@5: 93.04%
[2023-08-26 14:01:50 trainLogger INFO] : epoch: 79/100, batch: 157/195, lr: 0.0107, loss 0.8349, grad_norm 0.63, Acc@1: 90.64%, Acc@5: 94.01%
[2023-08-26 14:01:53 trainLogger INFO] : epoch: 79/100, batch: 195/195, lr: 0.0105, loss 1.0232, grad_norm 0.61, Acc@1: 90.52%, Acc@5: 94.19%
[2023-08-26 14:01:53 trainLogger INFO] : EPOCH 79 training takes 0:00:15
[2023-08-26 14:01:54 trainLogger INFO] : [epoch 79] Acc@1: 70.98%, Acc@5: 90.12%, loss: 1.3307
[2023-08-26 14:01:55 trainLogger INFO] : epoch: 80/100, batch: 1/195, lr: 0.0105, loss 0.8485, grad_norm 0.77, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:01:58 trainLogger INFO] : epoch: 80/100, batch: 40/195, lr: 0.0103, loss 2.2171, grad_norm 1.61, Acc@1: 88.37%, Acc@5: 91.95%
[2023-08-26 14:02:01 trainLogger INFO] : epoch: 80/100, batch: 79/195, lr: 0.0101, loss 0.8377, grad_norm 0.68, Acc@1: 90.32%, Acc@5: 93.72%
[2023-08-26 14:02:04 trainLogger INFO] : epoch: 80/100, batch: 118/195, lr: 0.0099, loss 0.8316, grad_norm 0.51, Acc@1: 88.27%, Acc@5: 92.60%
[2023-08-26 14:02:07 trainLogger INFO] : epoch: 80/100, batch: 157/195, lr: 0.0097, loss 0.8251, grad_norm 0.44, Acc@1: 90.59%, Acc@5: 94.33%
[2023-08-26 14:02:10 trainLogger INFO] : epoch: 80/100, batch: 195/195, lr: 0.0096, loss 0.8406, grad_norm 0.63, Acc@1: 89.38%, Acc@5: 93.38%
[2023-08-26 14:02:10 trainLogger INFO] : EPOCH 80 training takes 0:00:15
[2023-08-26 14:02:11 trainLogger INFO] : [epoch 80] Acc@1: 70.67%, Acc@5: 90.11%, loss: 1.3556
[2023-08-26 14:02:12 trainLogger INFO] : epoch: 81/100, batch: 1/195, lr: 0.0095, loss 0.8457, grad_norm 0.68, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:02:15 trainLogger INFO] : epoch: 81/100, batch: 40/195, lr: 0.0094, loss 0.8266, grad_norm 0.49, Acc@1: 81.54%, Acc@5: 87.16%
[2023-08-26 14:02:18 trainLogger INFO] : epoch: 81/100, batch: 79/195, lr: 0.0092, loss 0.8569, grad_norm 0.80, Acc@1: 84.52%, Acc@5: 90.11%
[2023-08-26 14:02:21 trainLogger INFO] : epoch: 81/100, batch: 118/195, lr: 0.0090, loss 0.8276, grad_norm 0.47, Acc@1: 86.00%, Acc@5: 90.78%
[2023-08-26 14:02:24 trainLogger INFO] : epoch: 81/100, batch: 157/195, lr: 0.0088, loss 0.8528, grad_norm 0.75, Acc@1: 88.05%, Acc@5: 92.35%
[2023-08-26 14:02:27 trainLogger INFO] : epoch: 81/100, batch: 195/195, lr: 0.0087, loss 0.8349, grad_norm 0.58, Acc@1: 87.75%, Acc@5: 92.30%
[2023-08-26 14:02:27 trainLogger INFO] : EPOCH 81 training takes 0:00:15
[2023-08-26 14:02:29 trainLogger INFO] : [epoch 81] Acc@1: 71.17%, Acc@5: 90.53%, loss: 1.3181
[2023-08-26 14:02:29 trainLogger INFO] : epoch: 82/100, batch: 1/195, lr: 0.0086, loss 0.8330, grad_norm 0.58, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 14:02:33 trainLogger INFO] : epoch: 82/100, batch: 40/195, lr: 0.0085, loss 0.8396, grad_norm 0.64, Acc@1: 84.16%, Acc@5: 89.75%
[2023-08-26 14:02:36 trainLogger INFO] : epoch: 82/100, batch: 79/195, lr: 0.0083, loss 2.5527, grad_norm 2.03, Acc@1: 85.86%, Acc@5: 91.39%
[2023-08-26 14:02:39 trainLogger INFO] : epoch: 82/100, batch: 118/195, lr: 0.0081, loss 2.5435, grad_norm 2.02, Acc@1: 85.98%, Acc@5: 91.20%
[2023-08-26 14:02:42 trainLogger INFO] : epoch: 82/100, batch: 157/195, lr: 0.0080, loss 1.2562, grad_norm 1.03, Acc@1: 87.59%, Acc@5: 92.52%
[2023-08-26 14:02:45 trainLogger INFO] : epoch: 82/100, batch: 195/195, lr: 0.0078, loss 0.8392, grad_norm 0.64, Acc@1: 87.84%, Acc@5: 92.72%
[2023-08-26 14:02:45 trainLogger INFO] : EPOCH 82 training takes 0:00:15
[2023-08-26 14:02:46 trainLogger INFO] : [epoch 82] Acc@1: 71.25%, Acc@5: 90.34%, loss: 1.3269
[2023-08-26 14:02:47 trainLogger INFO] : epoch: 83/100, batch: 1/195, lr: 0.0078, loss 0.8456, grad_norm 0.71, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:02:50 trainLogger INFO] : epoch: 83/100, batch: 40/195, lr: 0.0076, loss 3.1462, grad_norm 3.08, Acc@1: 84.38%, Acc@5: 89.74%
[2023-08-26 14:02:53 trainLogger INFO] : epoch: 83/100, batch: 79/195, lr: 0.0075, loss 0.8336, grad_norm 0.57, Acc@1: 85.39%, Acc@5: 91.02%
[2023-08-26 14:02:56 trainLogger INFO] : epoch: 83/100, batch: 118/195, lr: 0.0073, loss 0.8262, grad_norm 0.47, Acc@1: 89.18%, Acc@5: 93.75%
[2023-08-26 14:02:59 trainLogger INFO] : epoch: 83/100, batch: 157/195, lr: 0.0071, loss 0.8386, grad_norm 0.69, Acc@1: 89.78%, Acc@5: 94.09%
[2023-08-26 14:03:02 trainLogger INFO] : epoch: 83/100, batch: 195/195, lr: 0.0070, loss 0.8379, grad_norm 0.64, Acc@1: 90.55%, Acc@5: 94.57%
[2023-08-26 14:03:02 trainLogger INFO] : EPOCH 83 training takes 0:00:15
[2023-08-26 14:03:04 trainLogger INFO] : [epoch 83] Acc@1: 71.12%, Acc@5: 90.30%, loss: 1.3270
[2023-08-26 14:03:04 trainLogger INFO] : epoch: 84/100, batch: 1/195, lr: 0.0070, loss 0.8591, grad_norm 0.81, Acc@1: 99.22%, Acc@5: 99.61%
[2023-08-26 14:03:07 trainLogger INFO] : epoch: 84/100, batch: 40/195, lr: 0.0068, loss 2.4761, grad_norm 1.99, Acc@1: 88.60%, Acc@5: 95.68%
[2023-08-26 14:03:10 trainLogger INFO] : epoch: 84/100, batch: 79/195, lr: 0.0066, loss 0.8340, grad_norm 0.68, Acc@1: 86.35%, Acc@5: 92.66%
[2023-08-26 14:03:13 trainLogger INFO] : epoch: 84/100, batch: 118/195, lr: 0.0065, loss 1.7824, grad_norm 0.99, Acc@1: 87.14%, Acc@5: 93.12%
[2023-08-26 14:03:16 trainLogger INFO] : epoch: 84/100, batch: 157/195, lr: 0.0063, loss 0.8449, grad_norm 0.72, Acc@1: 87.41%, Acc@5: 93.54%
[2023-08-26 14:03:19 trainLogger INFO] : epoch: 84/100, batch: 195/195, lr: 0.0062, loss 0.8262, grad_norm 0.54, Acc@1: 87.72%, Acc@5: 93.44%
[2023-08-26 14:03:19 trainLogger INFO] : EPOCH 84 training takes 0:00:15
[2023-08-26 14:03:21 trainLogger INFO] : [epoch 84] Acc@1: 71.13%, Acc@5: 90.60%, loss: 1.3237
[2023-08-26 14:03:22 trainLogger INFO] : epoch: 85/100, batch: 1/195, lr: 0.0062, loss 0.8322, grad_norm 0.64, Acc@1: 99.61%, Acc@5: 100.00%
[2023-08-26 14:03:25 trainLogger INFO] : epoch: 85/100, batch: 40/195, lr: 0.0060, loss 0.8804, grad_norm 0.77, Acc@1: 84.20%, Acc@5: 87.83%
[2023-08-26 14:03:28 trainLogger INFO] : epoch: 85/100, batch: 79/195, lr: 0.0059, loss 0.8250, grad_norm 0.45, Acc@1: 88.76%, Acc@5: 92.83%
[2023-08-26 14:03:31 trainLogger INFO] : epoch: 85/100, batch: 118/195, lr: 0.0057, loss 1.4255, grad_norm 0.92, Acc@1: 86.63%, Acc@5: 91.25%
[2023-08-26 14:03:34 trainLogger INFO] : epoch: 85/100, batch: 157/195, lr: 0.0056, loss 0.8196, grad_norm 0.38, Acc@1: 87.89%, Acc@5: 92.04%
[2023-08-26 14:03:37 trainLogger INFO] : epoch: 85/100, batch: 195/195, lr: 0.0055, loss 0.8375, grad_norm 0.64, Acc@1: 87.50%, Acc@5: 92.21%
[2023-08-26 14:03:37 trainLogger INFO] : EPOCH 85 training takes 0:00:15
[2023-08-26 14:03:38 trainLogger INFO] : [epoch 85] Acc@1: 70.99%, Acc@5: 90.05%, loss: 1.3335
[2023-08-26 14:03:39 trainLogger INFO] : epoch: 86/100, batch: 1/195, lr: 0.0054, loss 2.2549, grad_norm 1.52, Acc@1: 92.97%, Acc@5: 99.22%
[2023-08-26 14:03:42 trainLogger INFO] : epoch: 86/100, batch: 40/195, lr: 0.0053, loss 1.5815, grad_norm 1.31, Acc@1: 85.28%, Acc@5: 91.55%
[2023-08-26 14:03:45 trainLogger INFO] : epoch: 86/100, batch: 79/195, lr: 0.0052, loss 0.8355, grad_norm 0.61, Acc@1: 85.49%, Acc@5: 91.09%
[2023-08-26 14:03:48 trainLogger INFO] : epoch: 86/100, batch: 118/195, lr: 0.0050, loss 0.8486, grad_norm 0.78, Acc@1: 83.79%, Acc@5: 89.32%
[2023-08-26 14:03:51 trainLogger INFO] : epoch: 86/100, batch: 157/195, lr: 0.0049, loss 0.8453, grad_norm 0.76, Acc@1: 83.77%, Acc@5: 89.09%
[2023-08-26 14:03:54 trainLogger INFO] : epoch: 86/100, batch: 195/195, lr: 0.0048, loss 0.8337, grad_norm 0.57, Acc@1: 83.75%, Acc@5: 89.00%
[2023-08-26 14:03:54 trainLogger INFO] : EPOCH 86 training takes 0:00:15
[2023-08-26 14:03:56 trainLogger INFO] : [epoch 86] Acc@1: 71.09%, Acc@5: 90.26%, loss: 1.3295
[2023-08-26 14:03:56 trainLogger INFO] : epoch: 87/100, batch: 1/195, lr: 0.0048, loss 0.8230, grad_norm 0.46, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:03:59 trainLogger INFO] : epoch: 87/100, batch: 40/195, lr: 0.0046, loss 0.8433, grad_norm 0.68, Acc@1: 84.83%, Acc@5: 90.27%
[2023-08-26 14:04:02 trainLogger INFO] : epoch: 87/100, batch: 79/195, lr: 0.0045, loss 1.6793, grad_norm 1.22, Acc@1: 85.17%, Acc@5: 90.01%
[2023-08-26 14:04:05 trainLogger INFO] : epoch: 87/100, batch: 118/195, lr: 0.0044, loss 0.8284, grad_norm 0.54, Acc@1: 87.01%, Acc@5: 91.54%
[2023-08-26 14:04:08 trainLogger INFO] : epoch: 87/100, batch: 157/195, lr: 0.0042, loss 0.8376, grad_norm 0.68, Acc@1: 85.61%, Acc@5: 90.25%
[2023-08-26 14:04:11 trainLogger INFO] : epoch: 87/100, batch: 195/195, lr: 0.0041, loss 0.8199, grad_norm 0.36, Acc@1: 84.53%, Acc@5: 89.69%
[2023-08-26 14:04:12 trainLogger INFO] : EPOCH 87 training takes 0:00:15
[2023-08-26 14:04:13 trainLogger INFO] : [epoch 87] Acc@1: 71.15%, Acc@5: 90.22%, loss: 1.3398
[2023-08-26 14:04:14 trainLogger INFO] : epoch: 88/100, batch: 1/195, lr: 0.0041, loss 2.2454, grad_norm 1.74, Acc@1: 90.23%, Acc@5: 98.05%
[2023-08-26 14:04:17 trainLogger INFO] : epoch: 88/100, batch: 40/195, lr: 0.0040, loss 0.8369, grad_norm 0.65, Acc@1: 95.39%, Acc@5: 97.75%
[2023-08-26 14:04:20 trainLogger INFO] : epoch: 88/100, batch: 79/195, lr: 0.0039, loss 0.8525, grad_norm 0.81, Acc@1: 88.11%, Acc@5: 92.36%
[2023-08-26 14:04:23 trainLogger INFO] : epoch: 88/100, batch: 118/195, lr: 0.0037, loss 0.8230, grad_norm 0.52, Acc@1: 90.18%, Acc@5: 93.90%
[2023-08-26 14:04:26 trainLogger INFO] : epoch: 88/100, batch: 157/195, lr: 0.0036, loss 0.8341, grad_norm 0.56, Acc@1: 89.58%, Acc@5: 93.47%
[2023-08-26 14:04:29 trainLogger INFO] : epoch: 88/100, batch: 195/195, lr: 0.0035, loss 0.8194, grad_norm 0.46, Acc@1: 89.51%, Acc@5: 93.31%
[2023-08-26 14:04:29 trainLogger INFO] : EPOCH 88 training takes 0:00:15
[2023-08-26 14:04:30 trainLogger INFO] : [epoch 88] Acc@1: 71.33%, Acc@5: 90.56%, loss: 1.3184
[2023-08-26 14:04:31 trainLogger INFO] : epoch: 89/100, batch: 1/195, lr: 0.0035, loss 0.8305, grad_norm 0.59, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:04:34 trainLogger INFO] : epoch: 89/100, batch: 40/195, lr: 0.0034, loss 1.1253, grad_norm 0.51, Acc@1: 85.65%, Acc@5: 90.27%
[2023-08-26 14:04:37 trainLogger INFO] : epoch: 89/100, batch: 79/195, lr: 0.0033, loss 0.8365, grad_norm 0.65, Acc@1: 85.71%, Acc@5: 90.05%
[2023-08-26 14:04:40 trainLogger INFO] : epoch: 89/100, batch: 118/195, lr: 0.0032, loss 0.8192, grad_norm 0.41, Acc@1: 86.29%, Acc@5: 90.94%
[2023-08-26 14:04:43 trainLogger INFO] : epoch: 89/100, batch: 157/195, lr: 0.0031, loss 0.8275, grad_norm 0.61, Acc@1: 86.93%, Acc@5: 91.26%
[2023-08-26 14:04:46 trainLogger INFO] : epoch: 89/100, batch: 195/195, lr: 0.0030, loss 2.7264, grad_norm 2.24, Acc@1: 85.86%, Acc@5: 90.67%
[2023-08-26 14:04:46 trainLogger INFO] : EPOCH 89 training takes 0:00:15
[2023-08-26 14:04:48 trainLogger INFO] : [epoch 89] Acc@1: 71.05%, Acc@5: 90.33%, loss: 1.3647
[2023-08-26 14:04:48 trainLogger INFO] : epoch: 90/100, batch: 1/195, lr: 0.0030, loss 1.9845, grad_norm 1.28, Acc@1: 0.00%, Acc@5: 8.98%
[2023-08-26 14:04:51 trainLogger INFO] : epoch: 90/100, batch: 40/195, lr: 0.0029, loss 2.7162, grad_norm 2.14, Acc@1: 83.05%, Acc@5: 89.79%
[2023-08-26 14:04:54 trainLogger INFO] : epoch: 90/100, batch: 79/195, lr: 0.0027, loss 0.8263, grad_norm 0.54, Acc@1: 85.91%, Acc@5: 92.25%
[2023-08-26 14:04:57 trainLogger INFO] : epoch: 90/100, batch: 118/195, lr: 0.0026, loss 2.5522, grad_norm 2.04, Acc@1: 84.00%, Acc@5: 90.57%
[2023-08-26 14:05:00 trainLogger INFO] : epoch: 90/100, batch: 157/195, lr: 0.0025, loss 0.8223, grad_norm 0.48, Acc@1: 84.02%, Acc@5: 89.94%
[2023-08-26 14:05:03 trainLogger INFO] : epoch: 90/100, batch: 195/195, lr: 0.0024, loss 3.0471, grad_norm 3.18, Acc@1: 85.06%, Acc@5: 90.74%
[2023-08-26 14:05:04 trainLogger INFO] : EPOCH 90 training takes 0:00:15
[2023-08-26 14:05:05 trainLogger INFO] : [epoch 90] Acc@1: 71.02%, Acc@5: 90.07%, loss: 1.3622
[2023-08-26 14:05:06 trainLogger INFO] : epoch: 91/100, batch: 1/195, lr: 0.0024, loss 0.8249, grad_norm 0.50, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:05:09 trainLogger INFO] : epoch: 91/100, batch: 40/195, lr: 0.0024, loss 1.6382, grad_norm 0.77, Acc@1: 92.20%, Acc@5: 96.04%
[2023-08-26 14:05:12 trainLogger INFO] : epoch: 91/100, batch: 79/195, lr: 0.0023, loss 0.8235, grad_norm 0.54, Acc@1: 88.91%, Acc@5: 93.33%
[2023-08-26 14:05:15 trainLogger INFO] : epoch: 91/100, batch: 118/195, lr: 0.0022, loss 0.8460, grad_norm 0.78, Acc@1: 86.73%, Acc@5: 91.05%
[2023-08-26 14:05:18 trainLogger INFO] : epoch: 91/100, batch: 157/195, lr: 0.0021, loss 0.8250, grad_norm 0.50, Acc@1: 87.75%, Acc@5: 92.10%
[2023-08-26 14:05:21 trainLogger INFO] : epoch: 91/100, batch: 195/195, lr: 0.0020, loss 0.8227, grad_norm 0.54, Acc@1: 88.10%, Acc@5: 92.45%
[2023-08-26 14:05:21 trainLogger INFO] : EPOCH 91 training takes 0:00:15
[2023-08-26 14:05:22 trainLogger INFO] : [epoch 91] Acc@1: 71.10%, Acc@5: 90.29%, loss: 1.3524
[2023-08-26 14:05:23 trainLogger INFO] : epoch: 92/100, batch: 1/195, lr: 0.0020, loss 0.8269, grad_norm 0.60, Acc@1: 98.83%, Acc@5: 100.00%
[2023-08-26 14:05:26 trainLogger INFO] : epoch: 92/100, batch: 40/195, lr: 0.0019, loss 2.7626, grad_norm 2.22, Acc@1: 95.20%, Acc@5: 98.55%
[2023-08-26 14:05:29 trainLogger INFO] : epoch: 92/100, batch: 79/195, lr: 0.0018, loss 0.8253, grad_norm 0.60, Acc@1: 87.95%, Acc@5: 92.64%
[2023-08-26 14:05:32 trainLogger INFO] : epoch: 92/100, batch: 118/195, lr: 0.0017, loss 0.8278, grad_norm 0.54, Acc@1: 87.22%, Acc@5: 91.78%
[2023-08-26 14:05:35 trainLogger INFO] : epoch: 92/100, batch: 157/195, lr: 0.0016, loss 0.8478, grad_norm 0.82, Acc@1: 86.22%, Acc@5: 91.01%
[2023-08-26 14:05:38 trainLogger INFO] : epoch: 92/100, batch: 195/195, lr: 0.0016, loss 0.8185, grad_norm 0.39, Acc@1: 85.87%, Acc@5: 90.88%
[2023-08-26 14:05:38 trainLogger INFO] : EPOCH 92 training takes 0:00:15
[2023-08-26 14:05:40 trainLogger INFO] : [epoch 92] Acc@1: 71.33%, Acc@5: 90.47%, loss: 1.3288
[2023-08-26 14:05:40 trainLogger INFO] : epoch: 93/100, batch: 1/195, lr: 0.0016, loss 0.8206, grad_norm 0.39, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:05:43 trainLogger INFO] : epoch: 93/100, batch: 40/195, lr: 0.0015, loss 2.6092, grad_norm 1.99, Acc@1: 92.46%, Acc@5: 95.81%
[2023-08-26 14:05:46 trainLogger INFO] : epoch: 93/100, batch: 79/195, lr: 0.0014, loss 0.8321, grad_norm 0.63, Acc@1: 91.09%, Acc@5: 94.00%
[2023-08-26 14:05:49 trainLogger INFO] : epoch: 93/100, batch: 118/195, lr: 0.0013, loss 0.8373, grad_norm 0.75, Acc@1: 89.55%, Acc@5: 93.12%
[2023-08-26 14:05:53 trainLogger INFO] : epoch: 93/100, batch: 157/195, lr: 0.0013, loss 0.8257, grad_norm 0.54, Acc@1: 88.41%, Acc@5: 92.32%
[2023-08-26 14:05:55 trainLogger INFO] : epoch: 93/100, batch: 195/195, lr: 0.0012, loss 0.8235, grad_norm 0.53, Acc@1: 87.18%, Acc@5: 91.23%
[2023-08-26 14:05:56 trainLogger INFO] : EPOCH 93 training takes 0:00:15
[2023-08-26 14:05:57 trainLogger INFO] : [epoch 93] Acc@1: 71.22%, Acc@5: 90.38%, loss: 1.3415
[2023-08-26 14:05:58 trainLogger INFO] : epoch: 94/100, batch: 1/195, lr: 0.0012, loss 0.8297, grad_norm 0.58, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:06:01 trainLogger INFO] : epoch: 94/100, batch: 40/195, lr: 0.0011, loss 2.2567, grad_norm 1.54, Acc@1: 92.66%, Acc@5: 95.69%
[2023-08-26 14:06:04 trainLogger INFO] : epoch: 94/100, batch: 79/195, lr: 0.0011, loss 0.8190, grad_norm 0.46, Acc@1: 91.56%, Acc@5: 94.49%
[2023-08-26 14:06:07 trainLogger INFO] : epoch: 94/100, batch: 118/195, lr: 0.0010, loss 1.3167, grad_norm 0.60, Acc@1: 91.02%, Acc@5: 94.27%
[2023-08-26 14:06:10 trainLogger INFO] : epoch: 94/100, batch: 157/195, lr: 0.0009, loss 0.8238, grad_norm 0.52, Acc@1: 90.83%, Acc@5: 94.34%
[2023-08-26 14:06:13 trainLogger INFO] : epoch: 94/100, batch: 195/195, lr: 0.0009, loss 0.8170, grad_norm 0.43, Acc@1: 90.67%, Acc@5: 94.29%
[2023-08-26 14:06:13 trainLogger INFO] : EPOCH 94 training takes 0:00:15
[2023-08-26 14:06:15 trainLogger INFO] : [epoch 94] Acc@1: 71.44%, Acc@5: 90.36%, loss: 1.3373
[2023-08-26 14:06:15 trainLogger INFO] : epoch: 95/100, batch: 1/195, lr: 0.0009, loss 0.8321, grad_norm 0.60, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:06:18 trainLogger INFO] : epoch: 95/100, batch: 40/195, lr: 0.0008, loss 0.8232, grad_norm 0.49, Acc@1: 88.58%, Acc@5: 91.98%
[2023-08-26 14:06:21 trainLogger INFO] : epoch: 95/100, batch: 79/195, lr: 0.0008, loss 0.8307, grad_norm 0.57, Acc@1: 87.80%, Acc@5: 92.68%
[2023-08-26 14:06:24 trainLogger INFO] : epoch: 95/100, batch: 118/195, lr: 0.0007, loss 2.1281, grad_norm 1.59, Acc@1: 88.14%, Acc@5: 92.35%
[2023-08-26 14:06:27 trainLogger INFO] : epoch: 95/100, batch: 157/195, lr: 0.0007, loss 0.8354, grad_norm 0.62, Acc@1: 89.17%, Acc@5: 93.18%
[2023-08-26 14:06:30 trainLogger INFO] : epoch: 95/100, batch: 195/195, lr: 0.0006, loss 2.7032, grad_norm 2.12, Acc@1: 89.04%, Acc@5: 93.08%
[2023-08-26 14:06:30 trainLogger INFO] : EPOCH 95 training takes 0:00:15
[2023-08-26 14:06:32 trainLogger INFO] : [epoch 95] Acc@1: 71.46%, Acc@5: 90.41%, loss: 1.3381
[2023-08-26 14:06:33 trainLogger INFO] : epoch: 96/100, batch: 1/195, lr: 0.0006, loss 1.5245, grad_norm 1.23, Acc@1: 98.05%, Acc@5: 100.00%
[2023-08-26 14:06:36 trainLogger INFO] : epoch: 96/100, batch: 40/195, lr: 0.0006, loss 2.2916, grad_norm 1.53, Acc@1: 79.89%, Acc@5: 86.45%
[2023-08-26 14:06:39 trainLogger INFO] : epoch: 96/100, batch: 79/195, lr: 0.0005, loss 0.8278, grad_norm 0.56, Acc@1: 84.21%, Acc@5: 89.74%
[2023-08-26 14:06:42 trainLogger INFO] : epoch: 96/100, batch: 118/195, lr: 0.0005, loss 3.1482, grad_norm 2.54, Acc@1: 83.51%, Acc@5: 89.35%
[2023-08-26 14:06:45 trainLogger INFO] : epoch: 96/100, batch: 157/195, lr: 0.0004, loss 2.8073, grad_norm 2.10, Acc@1: 85.08%, Acc@5: 90.64%
[2023-08-26 14:06:48 trainLogger INFO] : epoch: 96/100, batch: 195/195, lr: 0.0004, loss 0.8230, grad_norm 0.50, Acc@1: 84.34%, Acc@5: 89.76%
[2023-08-26 14:06:48 trainLogger INFO] : EPOCH 96 training takes 0:00:15
[2023-08-26 14:06:49 trainLogger INFO] : [epoch 96] Acc@1: 71.10%, Acc@5: 90.27%, loss: 1.3382
[2023-08-26 14:06:50 trainLogger INFO] : epoch: 97/100, batch: 1/195, lr: 0.0004, loss 0.8404, grad_norm 0.70, Acc@1: 99.22%, Acc@5: 100.00%
[2023-08-26 14:06:53 trainLogger INFO] : epoch: 97/100, batch: 40/195, lr: 0.0004, loss 1.9110, grad_norm 1.16, Acc@1: 81.05%, Acc@5: 85.09%
[2023-08-26 14:06:56 trainLogger INFO] : epoch: 97/100, batch: 79/195, lr: 0.0003, loss 2.4921, grad_norm 1.78, Acc@1: 85.47%, Acc@5: 89.25%
[2023-08-26 14:06:59 trainLogger INFO] : epoch: 97/100, batch: 118/195, lr: 0.0003, loss 2.5160, grad_norm 1.94, Acc@1: 87.92%, Acc@5: 91.18%
[2023-08-26 14:07:02 trainLogger INFO] : epoch: 97/100, batch: 157/195, lr: 0.0003, loss 0.8280, grad_norm 0.55, Acc@1: 88.11%, Acc@5: 91.31%
[2023-08-26 14:07:05 trainLogger INFO] : epoch: 97/100, batch: 195/195, lr: 0.0002, loss 0.8242, grad_norm 0.52, Acc@1: 86.58%, Acc@5: 90.32%
[2023-08-26 14:07:05 trainLogger INFO] : EPOCH 97 training takes 0:00:15
[2023-08-26 14:07:07 trainLogger INFO] : [epoch 97] Acc@1: 71.36%, Acc@5: 90.42%, loss: 1.3378
[2023-08-26 14:07:07 trainLogger INFO] : epoch: 98/100, batch: 1/195, lr: 0.0002, loss 2.7548, grad_norm 2.19, Acc@1: 58.20%, Acc@5: 89.45%
[2023-08-26 14:07:10 trainLogger INFO] : epoch: 98/100, batch: 40/195, lr: 0.0002, loss 2.4946, grad_norm 1.69, Acc@1: 82.37%, Acc@5: 87.16%
[2023-08-26 14:07:13 trainLogger INFO] : epoch: 98/100, batch: 79/195, lr: 0.0002, loss 1.4927, grad_norm 0.98, Acc@1: 87.33%, Acc@5: 90.90%
[2023-08-26 14:07:16 trainLogger INFO] : epoch: 98/100, batch: 118/195, lr: 0.0001, loss 0.8405, grad_norm 0.69, Acc@1: 87.45%, Acc@5: 91.21%
[2023-08-26 14:07:19 trainLogger INFO] : epoch: 98/100, batch: 157/195, lr: 0.0001, loss 2.5013, grad_norm 2.00, Acc@1: 87.88%, Acc@5: 91.84%
[2023-08-26 14:07:22 trainLogger INFO] : epoch: 98/100, batch: 195/195, lr: 0.0001, loss 0.8226, grad_norm 0.49, Acc@1: 87.41%, Acc@5: 91.89%
[2023-08-26 14:07:22 trainLogger INFO] : EPOCH 98 training takes 0:00:15
[2023-08-26 14:07:24 trainLogger INFO] : [epoch 98] Acc@1: 71.29%, Acc@5: 90.35%, loss: 1.3422
[2023-08-26 14:07:25 trainLogger INFO] : epoch: 99/100, batch: 1/195, lr: 0.0001, loss 0.8173, grad_norm 0.38, Acc@1: 100.00%, Acc@5: 100.00%
[2023-08-26 14:07:28 trainLogger INFO] : epoch: 99/100, batch: 40/195, lr: 0.0001, loss 2.8970, grad_norm 2.28, Acc@1: 83.93%, Acc@5: 87.73%
[2023-08-26 14:07:31 trainLogger INFO] : epoch: 99/100, batch: 79/195, lr: 0.0001, loss 1.4944, grad_norm 1.12, Acc@1: 83.82%, Acc@5: 86.80%
[2023-08-26 14:07:34 trainLogger INFO] : epoch: 99/100, batch: 118/195, lr: 0.0000, loss 0.8227, grad_norm 0.54, Acc@1: 85.20%, Acc@5: 88.59%
[2023-08-26 14:07:37 trainLogger INFO] : epoch: 99/100, batch: 157/195, lr: 0.0000, loss 1.1606, grad_norm 0.61, Acc@1: 86.10%, Acc@5: 89.62%
[2023-08-26 14:07:39 trainLogger INFO] : epoch: 99/100, batch: 195/195, lr: 0.0000, loss 0.8236, grad_norm 0.47, Acc@1: 86.31%, Acc@5: 90.05%
[2023-08-26 14:07:40 trainLogger INFO] : EPOCH 99 training takes 0:00:15
[2023-08-26 14:07:41 trainLogger INFO] : [epoch 99] Acc@1: 71.22%, Acc@5: 90.24%, loss: 1.3523
[2023-08-26 14:07:42 trainLogger INFO] : epoch: 100/100, batch: 1/195, lr: 0.0000, loss 2.7997, grad_norm 2.24, Acc@1: 51.17%, Acc@5: 85.94%
[2023-08-26 14:07:45 trainLogger INFO] : epoch: 100/100, batch: 40/195, lr: 0.0000, loss 2.8961, grad_norm 2.29, Acc@1: 90.32%, Acc@5: 94.89%
[2023-08-26 14:07:48 trainLogger INFO] : epoch: 100/100, batch: 79/195, lr: 0.0000, loss 1.2442, grad_norm 0.60, Acc@1: 88.71%, Acc@5: 93.07%
[2023-08-26 14:07:51 trainLogger INFO] : epoch: 100/100, batch: 118/195, lr: 0.0000, loss 0.8201, grad_norm 0.40, Acc@1: 89.14%, Acc@5: 93.61%
[2023-08-26 14:07:54 trainLogger INFO] : epoch: 100/100, batch: 157/195, lr: 0.0000, loss 2.0396, grad_norm 1.42, Acc@1: 88.13%, Acc@5: 93.09%
[2023-08-26 14:07:57 trainLogger INFO] : epoch: 100/100, batch: 195/195, lr: 0.0000, loss 0.8395, grad_norm 0.66, Acc@1: 89.53%, Acc@5: 93.90%
[2023-08-26 14:07:57 trainLogger INFO] : EPOCH 100 training takes 0:00:15
[2023-08-26 14:07:58 trainLogger INFO] : [epoch 100] Acc@1: 71.51%, Acc@5: 90.40%, loss: 1.3096
[2023-08-26 14:07:58 trainLogger INFO] : Training time 0:28:54
